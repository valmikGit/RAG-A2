import streamlit as st
import requests
import json
import os

# --- Configuration ---
# FastAPI service address
# For local development: localhost
# For Docker: use service name "backend"
FASTAPI_HOST = os.getenv("FASTAPI_HOST", "localhost")
FASTAPI_PORT = os.getenv("FASTAPI_PORT", "8000")
API_ENDPOINT = f"http://{FASTAPI_HOST}:{FASTAPI_PORT}/query"

st.write(f"ðŸ”— Connecting to backend at: {API_ENDPOINT}")

# --- Streamlit UI ---
st.set_page_config(page_title="Gemini RAG Chatbot", layout="wide")

st.title("ðŸ¤– Gemini RAG Chatbot")
st.markdown("Ask a question and get an answer grounded in the knowledge base (via FastAPI & ChromaDB).")

# Input field for user query
user_query = st.text_input("Enter your query:", key="query_input")

# Function to handle the API request
def fetch_rag_answer(query):
    try:
        # Send POST request to the FastAPI backend
        response = requests.post(
            API_ENDPOINT,
            json={"user_query": query},
            timeout=30  # Increased timeout for LLM generation
        )
        response.raise_for_status()  # Raise an exception for bad status codes (4xx or 5xx)
        return response.json()
    except requests.exceptions.ConnectionError:
        st.error(f"Connection Error: Could not connect to the backend service at {API_ENDPOINT}. Ensure the Docker containers are running.")
        return None
    except requests.exceptions.HTTPError as e:
        st.error(f"API Error: {e.response.status_code} - {e.response.text}")
        return None
    except Exception as e:
        st.error(f"An unexpected error occurred: {e}")
        return None

if st.button("Get RAG Answer"):
    if not user_query:
        st.warning("Please enter a query.")
    else:
        with st.spinner("Generating RAG answer..."):
            result = fetch_rag_answer(user_query)
            
            if result:
                # Display the answer
                st.subheader("Answer")
                st.info(result.get("answer", "No answer received."))
                
                # Display the contexts with metadata
                st.subheader("Contexts Used")
                contexts_with_metadata = result.get("contexts_with_metadata", [])
                
                if contexts_with_metadata:
                    for i, ctx_data in enumerate(contexts_with_metadata):
                        with st.container():
                            col1, col2 = st.columns([3, 1])
                            
                            with col1:
                                st.markdown(f"**ðŸ“„ Chunk {i+1}**")
                                text = ctx_data.get("text", "")
                                st.markdown(f"{text}")
                            
                            with col2:
                                metadata = ctx_data.get("metadata", {})
                                st.markdown("**ðŸ“Š Metadata**")
                                
                                # Display Act/Scene if available
                                if metadata.get("act"):
                                    st.markdown(f"**ðŸŽ­ Act:** {metadata['act']}")
                                if metadata.get("scene"):
                                    st.markdown(f"**ðŸŽ¬ Scene:** {metadata['scene']}")
                                
                                # Display page number
                                if metadata.get("page_number"):
                                    st.markdown(f"**ðŸ“– Page:** {metadata['page_number']}")
                                
                                # Display cleaned status
                                if metadata.get("cleaned"):
                                    st.markdown("**âœ… Cleaned**")
                            
                            st.divider()
                else:
                    # Fallback to old format if metadata not available
                    contexts = result.get("contexts", [])
                    if contexts:
                        for i, context in enumerate(contexts):
                            st.markdown(f"**Chunk {i+1}:** {context}")
                    else:
                        st.markdown("_No contexts were retrieved or used._")

# Optional: Display API endpoint status
st.sidebar.markdown("---")
st.sidebar.markdown(f"**Backend Endpoint:** `{API_ENDPOINT}`")