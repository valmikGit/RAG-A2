{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd26bf01",
   "metadata": {},
   "source": [
    "### Imports and Path setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e0d607ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import chromadb\n",
    "import pickle\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "multiquery_rag_output_path = \"../RAG Results/multiquery_rag_results.txt\"\n",
    "Relative_Database_path = \"./chroma_Data_v2\"\n",
    "Absolute_Database_path = Path(Relative_Database_path).resolve()\n",
    "file_path = \"../Chunking/Chunk_files/julius-caesar_chunks_semantic.pkl\"\n",
    "# Create a new collection with a unique name\n",
    "collection_name = \"anlp_rag_collection\"\n",
    "# # Set API key\n",
    "# os.environ[\"GOOGLE_API_KEY\"] = os.environ.get(\"GEMINI_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3b927c",
   "metadata": {},
   "source": [
    "### Chroma Setup and Chunk Loading\n",
    "Sets up persistant client and loads previously computed chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4b9b8be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] ChromaDB client initialized at: C:\\Users\\micro\\Desktop\\Abhinav college\\Resources\\Sem 7\\Advanced NLP\\Assignment 2\\RAG-A2\\VectorDB\\chroma_Data_v2\n",
      "Existing collections: ['anlp_rag_collection']\n"
     ]
    }
   ],
   "source": [
    "# Initialize the persistent client\n",
    "client = chromadb.PersistentClient(path=Absolute_Database_path)\n",
    "print(f\"[INFO] ChromaDB client initialized at: {Absolute_Database_path}\")\n",
    "\n",
    "# List existing collections\n",
    "existing_collections = client.list_collections()\n",
    "print(f\"Existing collections: {[c.name for c in existing_collections]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "788e6272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded 126 chunks from '../Chunking/Chunk_files/julius-caesar_chunks_semantic.pkl'.\n",
      "\n",
      "Here is the metadata of a loaded chunk:\n",
      "{'source': '../julius-caesar_PDF_FolgerShakespeare.pdf', 'page_number': 3, 'c': 'semantic', 'ischunk': True}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# No need for fitz or RecursiveCharacterTextSplitter here, as we are loading from a file.\n",
    "\n",
    "\n",
    "loaded_docs = []\n",
    "\n",
    "try:\n",
    "    with open(file_path, \"rb\") as f: # 'rb' mode for reading in binary\n",
    "        loaded_docs = pickle.load(f)\n",
    "    print(f\"Successfully loaded {len(loaded_docs)} chunks from '{file_path}'.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file '{file_path}' was not found.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading file: {e}\")\n",
    "\n",
    "# Now you can inspect the loaded documents to verify.\n",
    "print(\"\\nHere is the metadata of a loaded chunk:\")\n",
    "if loaded_docs:\n",
    "    print(loaded_docs[0].metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5cbb00",
   "metadata": {},
   "source": [
    "### Set up Embedding Function\n",
    "Will use default SentenceTransformer for generating embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "928a1da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding function initialized with model: all-MiniLM-L6-v2\n"
     ]
    }
   ],
   "source": [
    "# Install if needed\n",
    "# !pip install sentence_transformers\n",
    "\n",
    "# Set up embedding function\n",
    "from chromadb.utils.embedding_functions import SentenceTransformerEmbeddingFunction\n",
    "embedding_function = SentenceTransformerEmbeddingFunction(model_name=\"all-MiniLM-L6-v2\")\n",
    "print(\"Embedding function initialized with model: all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e9f44b",
   "metadata": {},
   "source": [
    "### Creating new Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3b34eceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Deleted existing collection 'anlp_rag_collection'\n",
      "[SUCCESS] Fresh collection 'anlp_rag_collection' created successfully\n",
      "Current count in collection: 0\n",
      "[SUCCESS] Fresh collection 'anlp_rag_collection' created successfully\n",
      "Current count in collection: 0\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# FORCE DELETE the collection if it exists\n",
    "try:\n",
    "    client.delete_collection(name=collection_name)\n",
    "    print(f\"[INFO] Deleted existing collection '{collection_name}'\")\n",
    "except Exception as e:\n",
    "    print(f\"[INFO] No existing collection named '{collection_name}' to delete.\")\n",
    "\n",
    "# Create a FRESH collection\n",
    "collection = client.create_collection(\n",
    "    name=collection_name,\n",
    "    embedding_function=embedding_function,\n",
    "    metadata={\n",
    "        \"description\": \"Julius Caesar Chunks collection for RAG\",\n",
    "        \"created\": str(datetime.now())\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f\"[SUCCESS] Fresh collection '{collection_name}' created successfully\")\n",
    "print(f\"Current count in collection: {collection.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b449ba",
   "metadata": {},
   "source": [
    "### Add data to collection\n",
    "The chunks have to be given an id and added to the collection now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "eaa83664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Generating IDs with prefix: julius-caesar\n",
      "[INFO] Prepared 126 documents with IDs like: julius-caesar_chunk_0, julius-caesar_chunk_1...\n",
      "[INFO] Added batch: 0 to 125 (126 documents)\n",
      "\n",
      "[SUCCESS] Added 126 documents to collection 'anlp_rag_collection'\n",
      "[INFO] All chunks have IDs in format: julius-caesar_chunk_<number>\n",
      "[INFO] Added batch: 0 to 125 (126 documents)\n",
      "\n",
      "[SUCCESS] Added 126 documents to collection 'anlp_rag_collection'\n",
      "[INFO] All chunks have IDs in format: julius-caesar_chunk_<number>\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "import hashlib\n",
    "\n",
    "# Extract document name from file path for ID generation\n",
    "# This will give us \"julius-caesar\" from the file path\n",
    "doc_name = file_path.split('/')[-1].split('_chunks')[0]\n",
    "\n",
    "# Prepare documents for ChromaDB\n",
    "ids = []\n",
    "documents = []\n",
    "metadatas = []\n",
    "\n",
    "print(f\"[INFO] Generating IDs with prefix: {doc_name}\")\n",
    "\n",
    "# Process each loaded document chunk\n",
    "for i, doc in enumerate(loaded_docs):\n",
    "    # Generate a deterministic ID based on document name and index\n",
    "    # This ensures all chunks from the same document have consistent IDs\n",
    "    doc_id = f\"{doc_name}_chunk_{i}\"\n",
    "    \n",
    "    # Get the document text\n",
    "    document_text = doc.page_content\n",
    "    \n",
    "    # Get the document metadata\n",
    "    metadata = doc.metadata\n",
    "    \n",
    "    # Add to our lists\n",
    "    ids.append(doc_id)\n",
    "    documents.append(document_text)\n",
    "    metadatas.append(metadata)\n",
    "\n",
    "print(f\"[INFO] Prepared {len(ids)} documents with IDs like: {ids[0]}, {ids[1] if len(ids) > 1 else 'N/A'}...\")\n",
    "\n",
    "# Add documents in batches to avoid memory issues\n",
    "batch_size = 500\n",
    "total_added = 0\n",
    "\n",
    "for i in range(0, len(ids), batch_size):\n",
    "    end_idx = min(i + batch_size, len(ids))\n",
    "    \n",
    "    # Simply add all documents (collection is fresh, no need to update)\n",
    "    collection.add(\n",
    "        ids=ids[i:end_idx],\n",
    "        documents=documents[i:end_idx],\n",
    "        metadatas=metadatas[i:end_idx]\n",
    "    )\n",
    "    \n",
    "    total_added += end_idx - i\n",
    "    print(f\"[INFO] Added batch: {i} to {end_idx-1} ({end_idx-i} documents)\")\n",
    "\n",
    "print(f\"\\n[SUCCESS] Added {total_added} documents to collection '{collection_name}'\")\n",
    "print(f\"[INFO] All chunks have IDs in format: {doc_name}_chunk_<number>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b1fd6408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total documents in collection: 126\n",
      "\n",
      "Sample entries:\n",
      "\n",
      "--- Document 1 ---\n",
      "ID: julius-caesar_chunk_0\n",
      "Text: Michael Witmore\n",
      "Director, Folger Shakespeare Library\n",
      "It is hard to imagine a world without Shakespea...\n",
      "Metadata: {'source': '../julius-caesar_PDF_FolgerShakespeare.pdf', 'page_number': 3, 'ischunk': True, 'c': 'semantic'}\n",
      "\n",
      "--- Document 2 ---\n",
      "ID: julius-caesar_chunk_1\n",
      "Text: Until now, with the release of The Folger Shakespeare (formerly\n",
      "Folger Digital Texts), readers in se...\n",
      "Metadata: {'c': 'semantic', 'source': '../julius-caesar_PDF_FolgerShakespeare.pdf', 'page_number': 4, 'ischunk': True}\n",
      "\n",
      "--- Document 3 ---\n",
      "ID: julius-caesar_chunk_2\n",
      "Text: At\n",
      "any point in the text, you can hover your cursor over a bracket for\n",
      "more information. Because the...\n",
      "Metadata: {'ischunk': True, 'page_number': 5, 'source': '../julius-caesar_PDF_FolgerShakespeare.pdf', 'c': 'semantic'}\n",
      "\n",
      "Sample entries:\n",
      "\n",
      "--- Document 1 ---\n",
      "ID: julius-caesar_chunk_0\n",
      "Text: Michael Witmore\n",
      "Director, Folger Shakespeare Library\n",
      "It is hard to imagine a world without Shakespea...\n",
      "Metadata: {'source': '../julius-caesar_PDF_FolgerShakespeare.pdf', 'page_number': 3, 'ischunk': True, 'c': 'semantic'}\n",
      "\n",
      "--- Document 2 ---\n",
      "ID: julius-caesar_chunk_1\n",
      "Text: Until now, with the release of The Folger Shakespeare (formerly\n",
      "Folger Digital Texts), readers in se...\n",
      "Metadata: {'c': 'semantic', 'source': '../julius-caesar_PDF_FolgerShakespeare.pdf', 'page_number': 4, 'ischunk': True}\n",
      "\n",
      "--- Document 3 ---\n",
      "ID: julius-caesar_chunk_2\n",
      "Text: At\n",
      "any point in the text, you can hover your cursor over a bracket for\n",
      "more information. Because the...\n",
      "Metadata: {'ischunk': True, 'page_number': 5, 'source': '../julius-caesar_PDF_FolgerShakespeare.pdf', 'c': 'semantic'}\n"
     ]
    }
   ],
   "source": [
    "# Check collection count\n",
    "count = collection.count()\n",
    "print(f\"Total documents in collection: {count}\")\n",
    "\n",
    "# Peek at the first few entries\n",
    "peek = collection.peek(limit=3)\n",
    "print(\"\\nSample entries:\")\n",
    "for i, (doc_id, doc_text, metadata) in enumerate(zip(\n",
    "    peek['ids'], peek['documents'], peek['metadatas']\n",
    ")):\n",
    "    print(f\"\\n--- Document {i+1} ---\")\n",
    "    print(f\"ID: {doc_id}\")\n",
    "    print(f\"Text: {doc_text[:100]}...\")\n",
    "    print(f\"Metadata: {metadata}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc47242",
   "metadata": {},
   "source": [
    "### Querying the Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "92ee0a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rich table for displaying results (optional but nice)\n",
    "try:\n",
    "    from rich.console import Console\n",
    "    from rich.table import Table\n",
    "    \n",
    "    console = Console()\n",
    "    use_rich = True\n",
    "except ImportError:\n",
    "    use_rich = False\n",
    "    print(\"Rich package not found. Using standard print.\")\n",
    "\n",
    "# Function to display query results\n",
    "def print_results(results, use_rich=use_rich):\n",
    "    if use_rich:\n",
    "        table = Table(show_header=True, header_style=\"bold magenta\")\n",
    "        table.add_column(\"Rank\", width=6)\n",
    "        table.add_column(\"Document ID\")\n",
    "        table.add_column(\"Document Text\", width=60)\n",
    "        table.add_column(\"Page\")\n",
    "        table.add_column(\"Distance\")\n",
    "        \n",
    "        docs = results['documents'][0]\n",
    "        ids = results['ids'][0]\n",
    "        metas = results['metadatas'][0]\n",
    "        distances = results['distances'][0]\n",
    "        \n",
    "        for i, (doc, doc_id, meta, dist) in enumerate(zip(docs, ids, metas, distances)):\n",
    "            table.add_row(\n",
    "                str(i+1),\n",
    "                doc_id,\n",
    "                (doc[:100] + \"...\") if len(doc) > 100 else doc,\n",
    "                str(meta.get('page_number', 'N/A')),\n",
    "                f\"{dist:.4f}\"\n",
    "            )\n",
    "        \n",
    "        console.print(table)\n",
    "    else:\n",
    "        # Standard print version\n",
    "        for i, (doc, meta, dist) in enumerate(zip(\n",
    "            results['documents'][0], \n",
    "            results['metadatas'][0], \n",
    "            results['distances'][0]\n",
    "        )):\n",
    "            print(f\"\\n--- Result {i+1} ---\")\n",
    "            print(f\"Text: {doc[:100]}...\")\n",
    "            print(f\"Metadata: {meta}\")\n",
    "            print(f\"Distance: {dist:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5ac82c7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for query: 'What themes are explored in Julius Caesar?'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━┳━━━━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Rank   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Document ID           </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Document Text                                                </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Page </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Distance </span>┃\n",
       "┡━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━╇━━━━━━━━━━┩\n",
       "│ 1      │ julius-caesar_chunk_… │ 95                                                           │ 51   │ 0.3517   │\n",
       "│        │                       │ Julius Caesar                                                │      │          │\n",
       "│        │                       │ ACT 3. SC. 1                                                 │      │          │\n",
       "│        │                       │ POPILIUS                                                     │      │          │\n",
       "│        │                       │ CASSIUS                                                      │      │          │\n",
       "│        │                       │ POPILIUS                                                     │      │          │\n",
       "│        │                       │ He walks away. BRUTUS                                        │      │          │\n",
       "│        │                       │ CASSIUS                                                      │      │          │\n",
       "│        │                       │ BRUTUS                                                       │      │          │\n",
       "│        │                       │ CASSIUS...                                                   │      │          │\n",
       "│ 2      │ julius-caesar_chunk_… │ CAESAR                                                       │ 50   │ 0.3766   │\n",
       "│        │                       │ SOOTHSAYER                                                   │      │          │\n",
       "│        │                       │ ARTEMIDORUS                                                  │      │          │\n",
       "│        │                       │ DECIUS                                                       │      │          │\n",
       "│        │                       │ ARTEMIDORUS                                                  │      │          │\n",
       "│        │                       │ CAESAR                                                       │      │          │\n",
       "│        │                       │ ARTEMIDORUS                                                  │      │          │\n",
       "│        │                       │ CAESAR                                                       │      │          │\n",
       "│        │                       │ PUBLIUS                                                      │      │          │\n",
       "│        │                       │ CASSIUS                                                      │      │          │\n",
       "│        │                       │ Caesar go...                                                 │      │          │\n",
       "│ 3      │ julius-caesar_chunk_… │ 85                                                           │ 47   │ 0.3788   │\n",
       "│        │                       │ Julius Caesar                                                │      │          │\n",
       "│        │                       │ ACT 2. SC. 4                                                 │      │          │\n",
       "│        │                       │ ARTEMIDORUS                                                  │      │          │\n",
       "│        │                       │  Thy lover,                                                  │      │          │\n",
       "│        │                       │  Artemidorus                                                 │      │          │\n",
       "│        │                       │ He exits. PORTIA                                             │      │          │\n",
       "│        │                       │ LUCIUS                                                       │      │          │\n",
       "│        │                       │ PORTIA                                                       │      │          │\n",
       "│        │                       │ En...                                                        │      │          │\n",
       "└────────┴───────────────────────┴──────────────────────────────────────────────────────────────┴──────┴──────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━┳━━━━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35mRank  \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mDocument ID          \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mDocument Text                                               \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mPage\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mDistance\u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━╇━━━━━━━━━━┩\n",
       "│ 1      │ julius-caesar_chunk_… │ 95                                                           │ 51   │ 0.3517   │\n",
       "│        │                       │ Julius Caesar                                                │      │          │\n",
       "│        │                       │ ACT 3. SC. 1                                                 │      │          │\n",
       "│        │                       │ POPILIUS                                                     │      │          │\n",
       "│        │                       │ CASSIUS                                                      │      │          │\n",
       "│        │                       │ POPILIUS                                                     │      │          │\n",
       "│        │                       │ He walks away. BRUTUS                                        │      │          │\n",
       "│        │                       │ CASSIUS                                                      │      │          │\n",
       "│        │                       │ BRUTUS                                                       │      │          │\n",
       "│        │                       │ CASSIUS...                                                   │      │          │\n",
       "│ 2      │ julius-caesar_chunk_… │ CAESAR                                                       │ 50   │ 0.3766   │\n",
       "│        │                       │ SOOTHSAYER                                                   │      │          │\n",
       "│        │                       │ ARTEMIDORUS                                                  │      │          │\n",
       "│        │                       │ DECIUS                                                       │      │          │\n",
       "│        │                       │ ARTEMIDORUS                                                  │      │          │\n",
       "│        │                       │ CAESAR                                                       │      │          │\n",
       "│        │                       │ ARTEMIDORUS                                                  │      │          │\n",
       "│        │                       │ CAESAR                                                       │      │          │\n",
       "│        │                       │ PUBLIUS                                                      │      │          │\n",
       "│        │                       │ CASSIUS                                                      │      │          │\n",
       "│        │                       │ Caesar go...                                                 │      │          │\n",
       "│ 3      │ julius-caesar_chunk_… │ 85                                                           │ 47   │ 0.3788   │\n",
       "│        │                       │ Julius Caesar                                                │      │          │\n",
       "│        │                       │ ACT 2. SC. 4                                                 │      │          │\n",
       "│        │                       │ ARTEMIDORUS                                                  │      │          │\n",
       "│        │                       │  Thy lover,                                                  │      │          │\n",
       "│        │                       │  Artemidorus                                                 │      │          │\n",
       "│        │                       │ He exits. PORTIA                                             │      │          │\n",
       "│        │                       │ LUCIUS                                                       │      │          │\n",
       "│        │                       │ PORTIA                                                       │      │          │\n",
       "│        │                       │ En...                                                        │      │          │\n",
       "└────────┴───────────────────────┴──────────────────────────────────────────────────────────────┴──────┴──────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run a sample query\n",
    "query = \"What themes are explored in Julius Caesar?\"\n",
    "results = collection.query(\n",
    "    query_texts=[query],\n",
    "    n_results=3,\n",
    "    include=[\"documents\", \"metadatas\", \"distances\"]\n",
    ")\n",
    "\n",
    "print(f\"\\nResults for query: '{query}'\")\n",
    "print_results(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb314ce",
   "metadata": {},
   "source": [
    "### Natural Language Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5dbc9b7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain 0.3.27 requires langchain-core<1.0.0,>=0.3.72, but you have langchain-core 1.0.4 which is incompatible.\n",
      "langchain-experimental 0.3.4 requires langchain-core<0.4.0,>=0.3.28, but you have langchain-core 1.0.4 which is incompatible.\n",
      "langchain-google-genai 2.0.10 requires langchain-core<0.4.0,>=0.3.37, but you have langchain-core 1.0.4 which is incompatible.\n",
      "langchain-openai 0.3.35 requires langchain-core<1.0.0,>=0.3.78, but you have langchain-core 1.0.4 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install groq --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "497764f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: langchain-groq 1.0.0\n",
      "Uninstalling langchain-groq-1.0.0:\n",
      "  Successfully uninstalled langchain-groq-1.0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain 0.3.27 requires langchain-core<1.0.0,>=0.3.72, but you have langchain-core 0.2.43 which is incompatible.\n",
      "langchain-community 0.3.31 requires langchain-core<2.0.0,>=0.3.78, but you have langchain-core 0.2.43 which is incompatible.\n",
      "langchain-experimental 0.3.4 requires langchain-core<0.4.0,>=0.3.28, but you have langchain-core 0.2.43 which is incompatible.\n",
      "langchain-google-genai 2.0.10 requires langchain-core<0.4.0,>=0.3.37, but you have langchain-core 0.2.43 which is incompatible.\n",
      "langchain-openai 0.3.35 requires langchain-core<1.0.0,>=0.3.78, but you have langchain-core 0.2.43 which is incompatible.\n",
      "langchain-text-splitters 0.3.11 requires langchain-core<2.0.0,>=0.3.75, but you have langchain-core 0.2.43 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "# Fix version conflicts - downgrade to compatible versions\n",
    "!pip uninstall langchain-groq -y\n",
    "!pip install \"langchain-core<0.3.0\" --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "20e7f9b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groq LLM initialized with model: llama-3.3-70b-versatile (using native Groq SDK)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from groq import Groq\n",
    "\n",
    "# Set the API key for Groq\n",
    "os.environ[\"GROQ_API_KEY\"] = \"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\"\n",
    "\n",
    "# Initialize Groq client\n",
    "groq_client = Groq(api_key=os.environ[\"GROQ_API_KEY\"])\n",
    "\n",
    "# Create a simple LLM wrapper that works like LangChain's ChatGroq\n",
    "class GroqLLM:\n",
    "    def __init__(self, model, temperature=0.7):\n",
    "        self.model = model\n",
    "        self.temperature = temperature\n",
    "        self.client = groq_client\n",
    "    \n",
    "    def invoke(self, prompt):\n",
    "        \"\"\"Invoke the LLM with a prompt and return response\"\"\"\n",
    "        # Handle both string prompts and LangChain PromptValue objects\n",
    "        if hasattr(prompt, 'to_string'):\n",
    "            prompt_text = prompt.to_string()\n",
    "        elif hasattr(prompt, 'text'):\n",
    "            prompt_text = prompt.text\n",
    "        else:\n",
    "            prompt_text = str(prompt)\n",
    "        \n",
    "        response = self.client.chat.completions.create(\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt_text}],\n",
    "            model=self.model,\n",
    "            temperature=self.temperature\n",
    "        )\n",
    "        \n",
    "        # Return an object with .content attribute for compatibility\n",
    "        class Response:\n",
    "            def __init__(self, content):\n",
    "                self.content = content\n",
    "            def __str__(self):\n",
    "                return self.content\n",
    "        \n",
    "        return Response(response.choices[0].message.content)\n",
    "\n",
    "# Initialize our custom LLM wrapper\n",
    "llm = GroqLLM(\n",
    "    model=\"llama-3.3-70b-versatile\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "print(\"Groq LLM initialized with model: llama-3.3-70b-versatile (using native Groq SDK)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dab6b7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Better prompt template for Julius Caesar\n",
    "rag_prompt_template = \"\"\"\n",
    "You are an expert on Shakespeare's Julius Caesar. Answer questions using ONLY the context below.\n",
    "If you can't find a complete answer in the context but see partial information, try to provide what you can find and acknowledge the limitations of the available information.\n",
    "If there is NO relevant information at all in the context, respond with \"I don't have enough information to answer this question.\"\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {query}\n",
    "\n",
    "Answer (based only on the context provided):\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=rag_prompt_template,\n",
    "    input_variables=[\"context\", \"query\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2ddfe3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install rank_bm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bb979b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rank_bm25 import BM25Okapi\n",
    "import numpy as np\n",
    "\n",
    "def answer_with_hybrid_rag(query, n_results=5):\n",
    "    # 1. Semantic search with ChromaDB\n",
    "    semantic_results = collection.query(\n",
    "        query_texts=[query],\n",
    "        n_results=n_results,\n",
    "        include=[\"documents\", \"metadatas\", \"distances\"]\n",
    "    )\n",
    "    \n",
    "    # 2. Perform keyword search with BM25\n",
    "    # First get all documents to search across\n",
    "    all_docs = collection.get(\n",
    "        limit=100,  # Adjust based on your collection size\n",
    "        include=[\"documents\", \"metadatas\"]\n",
    "    )\n",
    "    \n",
    "    # Tokenize for BM25\n",
    "    tokenized_docs = [doc.split() for doc in all_docs[\"documents\"]]\n",
    "    bm25 = BM25Okapi(tokenized_docs)\n",
    "    \n",
    "    # Get BM25 scores\n",
    "    tokenized_query = query.split()\n",
    "    bm25_scores = bm25.get_scores(tokenized_query)\n",
    "    \n",
    "    # Get top BM25 results\n",
    "    top_bm25_indices = np.argsort(bm25_scores)[-n_results:][::-1]\n",
    "    \n",
    "    # 3. Combine results (simple union)\n",
    "    combined_docs = []\n",
    "    combined_meta = []\n",
    "    combined_ids = [] \n",
    "    seen_ids = set()\n",
    "    \n",
    "    # Add semantic results\n",
    "    for doc, meta, doc_id in zip(\n",
    "        semantic_results[\"documents\"][0], \n",
    "        semantic_results[\"metadatas\"][0],\n",
    "        semantic_results[\"ids\"][0]\n",
    "    ):\n",
    "        if doc_id not in seen_ids:\n",
    "            combined_docs.append(doc)\n",
    "            combined_meta.append(meta)\n",
    "            combined_ids.append(doc_id)\n",
    "            seen_ids.add(doc_id)\n",
    "    \n",
    "    # Add keyword results\n",
    "    for idx in top_bm25_indices:\n",
    "        doc_id = all_docs[\"ids\"][idx]\n",
    "        if doc_id not in seen_ids:\n",
    "            combined_docs.append(all_docs[\"documents\"][idx])\n",
    "            combined_meta.append(all_docs[\"metadatas\"][idx])\n",
    "            combined_ids.append(doc_id)\n",
    "            seen_ids.add(doc_id)\n",
    "    \n",
    "    # Limit to n_results total\n",
    "    combined_docs = combined_docs[:n_results]\n",
    "    combined_meta = combined_meta[:n_results]\n",
    "    combined_ids = combined_ids[:n_results]\n",
    "    \n",
    "    # Format context and complete RAG as before\n",
    "    formatted_docs = []\n",
    "    for doc, meta in zip(combined_docs, combined_meta):\n",
    "        page_num = meta.get(\"page_number\", \"unknown\")\n",
    "        formatted_docs.append(f\"[Page {page_num}]: {doc}\")\n",
    "    \n",
    "    context = \"\\n\\n---\\n\\n\".join(formatted_docs)\n",
    "    filled_prompt = prompt.format(context=context, query=query)\n",
    "    response = llm.invoke(filled_prompt)\n",
    "    \n",
    "    # Create a mock results object for print_results compatibility\n",
    "    mock_results = {\n",
    "        \"documents\": [combined_docs],\n",
    "        \"metadatas\": [combined_meta],\n",
    "        \"distances\": [[0.0] * len(combined_docs)],  # Placeholder distances\n",
    "        \"ids\": [combined_ids]\n",
    "    }\n",
    "    \n",
    "    return {\n",
    "        \"query\": query,\n",
    "        \"answer\": response.content if hasattr(response, 'content') else str(response),\n",
    "        \"source_documents\": mock_results\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "960bba69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is the relationship between Brutus and Caesar?\n",
      "\n",
      "Answer: According to the context, Brutus and Caesar had a close relationship, with Caesar considering Brutus as his \"angel\" (Page 68). However, Brutus was involved in the conspiracy against Caesar and ultimately stabbed him, which is described as the \"most unkindest cut of all\" (Page 68). Brutus seems to have had mixed feelings about Caesar, as he questions Caesar's growing power and influence in Rome (Page 17), but also acknowledges the close relationship they had. Cassius also notes that Antony is \"making his peace\" with the conspirators, including Brutus, in Caesar's presence, suggesting that Brutus's actions were a betrayal of Caesar's trust (Page 58). Overall, the relationship between Brutus and Caesar is complex and marked by both affection and betrayal.\n",
      "\n",
      "Sources:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━┳━━━━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Rank   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Document ID           </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Document Text                                                </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Page </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Distance </span>┃\n",
       "┡━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━╇━━━━━━━━━━┩\n",
       "│ 1      │ julius-caesar_chunk_… │ 23                                                           │ 17   │ 0.0000   │\n",
       "│        │                       │ Julius Caesar                                                │      │          │\n",
       "│        │                       │ ACT 1. SC. 2                                                 │      │          │\n",
       "│        │                       │ BRUTUS                                                       │      │          │\n",
       "│        │                       │  “Brutus” and “Caesar”—what should be in that                │      │          │\n",
       "│        │                       │  “Caesar”? Why sh...                                         │      │          │\n",
       "│ 2      │ julius-caesar_chunk_… │ 85                                                           │ 47   │ 0.0000   │\n",
       "│        │                       │ Julius Caesar                                                │      │          │\n",
       "│        │                       │ ACT 2. SC. 4                                                 │      │          │\n",
       "│        │                       │ ARTEMIDORUS                                                  │      │          │\n",
       "│        │                       │  Thy lover,                                                  │      │          │\n",
       "│        │                       │  Artemidorus                                                 │      │          │\n",
       "│        │                       │ He exits. PORTIA                                             │      │          │\n",
       "│        │                       │ LUCIUS                                                       │      │          │\n",
       "│        │                       │ PORTIA                                                       │      │          │\n",
       "│        │                       │ En...                                                        │      │          │\n",
       "│ 3      │ julius-caesar_chunk_… │ Bear back! If you have tears, prepare to shed them now. You  │ 68   │ 0.0000   │\n",
       "│        │                       │ all do know this mantle. I remember                          │      │          │\n",
       "│        │                       │  The...                                                      │      │          │\n",
       "│ 4      │ julius-caesar_chunk_… │ 109                                                          │ 58   │ 0.0000   │\n",
       "│        │                       │ Julius Caesar                                                │      │          │\n",
       "│        │                       │ ACT 3. SC. 1                                                 │      │          │\n",
       "│        │                       │ CASSIUS                                                      │      │          │\n",
       "│        │                       │ ANTONY                                                       │      │          │\n",
       "│        │                       │ CASSIUS                                                      │      │          │\n",
       "│        │                       │ ANTONY                                                       │      │          │\n",
       "│        │                       │ BRUTUS                                                       │      │          │\n",
       "│        │                       │  Either a coward or a flatterer....                          │      │          │\n",
       "│ 5      │ julius-caesar_chunk_… │ 199                                                          │ 101  │ 0.0000   │\n",
       "│        │                       │ Julius Caesar                                                │      │          │\n",
       "│        │                       │ ACT 5. SC. 4                                                 │      │          │\n",
       "│        │                       │ They exit. BRUTUS                                            │      │          │\n",
       "│        │                       │ Brutus, Messala, and Flavius exit. CATO                      │      │          │\n",
       "│        │                       │ LUCILIUS                                                     │      │          │\n",
       "│        │                       │ Ca...                                                        │      │          │\n",
       "└────────┴───────────────────────┴──────────────────────────────────────────────────────────────┴──────┴──────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━┳━━━━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35mRank  \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mDocument ID          \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mDocument Text                                               \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mPage\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mDistance\u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━╇━━━━━━━━━━┩\n",
       "│ 1      │ julius-caesar_chunk_… │ 23                                                           │ 17   │ 0.0000   │\n",
       "│        │                       │ Julius Caesar                                                │      │          │\n",
       "│        │                       │ ACT 1. SC. 2                                                 │      │          │\n",
       "│        │                       │ BRUTUS                                                       │      │          │\n",
       "│        │                       │  “Brutus” and “Caesar”—what should be in that                │      │          │\n",
       "│        │                       │  “Caesar”? Why sh...                                         │      │          │\n",
       "│ 2      │ julius-caesar_chunk_… │ 85                                                           │ 47   │ 0.0000   │\n",
       "│        │                       │ Julius Caesar                                                │      │          │\n",
       "│        │                       │ ACT 2. SC. 4                                                 │      │          │\n",
       "│        │                       │ ARTEMIDORUS                                                  │      │          │\n",
       "│        │                       │  Thy lover,                                                  │      │          │\n",
       "│        │                       │  Artemidorus                                                 │      │          │\n",
       "│        │                       │ He exits. PORTIA                                             │      │          │\n",
       "│        │                       │ LUCIUS                                                       │      │          │\n",
       "│        │                       │ PORTIA                                                       │      │          │\n",
       "│        │                       │ En...                                                        │      │          │\n",
       "│ 3      │ julius-caesar_chunk_… │ Bear back! If you have tears, prepare to shed them now. You  │ 68   │ 0.0000   │\n",
       "│        │                       │ all do know this mantle. I remember                          │      │          │\n",
       "│        │                       │  The...                                                      │      │          │\n",
       "│ 4      │ julius-caesar_chunk_… │ 109                                                          │ 58   │ 0.0000   │\n",
       "│        │                       │ Julius Caesar                                                │      │          │\n",
       "│        │                       │ ACT 3. SC. 1                                                 │      │          │\n",
       "│        │                       │ CASSIUS                                                      │      │          │\n",
       "│        │                       │ ANTONY                                                       │      │          │\n",
       "│        │                       │ CASSIUS                                                      │      │          │\n",
       "│        │                       │ ANTONY                                                       │      │          │\n",
       "│        │                       │ BRUTUS                                                       │      │          │\n",
       "│        │                       │  Either a coward or a flatterer....                          │      │          │\n",
       "│ 5      │ julius-caesar_chunk_… │ 199                                                          │ 101  │ 0.0000   │\n",
       "│        │                       │ Julius Caesar                                                │      │          │\n",
       "│        │                       │ ACT 5. SC. 4                                                 │      │          │\n",
       "│        │                       │ They exit. BRUTUS                                            │      │          │\n",
       "│        │                       │ Brutus, Messala, and Flavius exit. CATO                      │      │          │\n",
       "│        │                       │ LUCILIUS                                                     │      │          │\n",
       "│        │                       │ Ca...                                                        │      │          │\n",
       "└────────┴───────────────────────┴──────────────────────────────────────────────────────────────┴──────┴──────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test our RAG pipeline with a question\n",
    "test_query = \"What is the relationship between Brutus and Caesar?\"\n",
    "response = answer_with_hybrid_rag(test_query)\n",
    "\n",
    "print(f\"Question: {test_query}\")\n",
    "print(f\"\\nAnswer: {response['answer']}\")\n",
    "print(\"\\nSources:\")\n",
    "print_results(response[\"source_documents\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1d52efee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Question: What are the main themes in Julius Caesar?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer: I don't have enough information to answer this question. The context provided focuses on specific scenes and dialogues from the play, but it does not provide a comprehensive overview of the main themes in Julius Caesar. However, some potential themes that can be inferred from the context include conspiracy, loyalty, power, and the consequences of one's actions, but a more detailed analysis of the play as a whole would be necessary to identify the main themes.\n",
      "\n",
      "Top source:\n",
      "[Page 51]:\n",
      "95\n",
      "Julius Caesar\n",
      "ACT 3. SC. 1\n",
      "POPILIUS\n",
      "CASSIUS\n",
      "POPILIUS\n",
      "He walks away. BRUTUS\n",
      "CASSIUS\n",
      "BRUTUS\n",
      "CASSIUS\n",
      "BRUTUS\n",
      "CASSIUS\n",
      "Trebonius and Antony exit. DECIUS\n",
      "BRUTUS\n",
      "CINNA\n",
      "CAESAR\n",
      "METELLUS\n",
      ", to Cassius\n",
      " \n",
      " I wis...\n",
      "\n",
      "==================================================\n",
      "Question: How does Brutus justify killing Caesar?\n",
      "\n",
      "Answer: According to the context, Brutus justifies killing Caesar by stating that he slew his \"best lover\" (Caesar) \"for the good of Rome\" and that he has \"the same dagger for myself when it shall please my country to need my death\" (Page 63, Act 3, Scene 2). This implies that Brutus believes the assassination was necessary for the well-being of Rome and that he is willing to sacrifice himself if needed. However, the context does not provide a detailed explanation of Brutus' motivations or the specific reasons why he considered Caesar a threat to Rome.\n",
      "\n",
      "Top source:\n",
      "[Page 63]:\n",
      "119\n",
      "Julius Caesar\n",
      "ACT 3. SC. 2\n",
      "PLEBEIANS\n",
      "FIRST PLEBEIAN\n",
      "SECOND PLEBEIAN\n",
      "THIRD PLEBEIAN\n",
      "FOURTH PLEBEIAN\n",
      "FIRST PLEBEIAN\n",
      "BRUTUS\n",
      "SECOND PLEBEIAN\n",
      "FIRST PLEBEIAN\n",
      "BRUTUS\n",
      " more to Caesar than you shall do to ...\n",
      "\n",
      "==================================================\n",
      "Question: What role does Cassius play in the conspiracy?\n",
      "\n",
      "Answer: According to the context, Brutus justifies killing Caesar by stating that he slew his \"best lover\" (Caesar) \"for the good of Rome\" and that he has \"the same dagger for myself when it shall please my country to need my death\" (Page 63, Act 3, Scene 2). This implies that Brutus believes the assassination was necessary for the well-being of Rome and that he is willing to sacrifice himself if needed. However, the context does not provide a detailed explanation of Brutus' motivations or the specific reasons why he considered Caesar a threat to Rome.\n",
      "\n",
      "Top source:\n",
      "[Page 63]:\n",
      "119\n",
      "Julius Caesar\n",
      "ACT 3. SC. 2\n",
      "PLEBEIANS\n",
      "FIRST PLEBEIAN\n",
      "SECOND PLEBEIAN\n",
      "THIRD PLEBEIAN\n",
      "FOURTH PLEBEIAN\n",
      "FIRST PLEBEIAN\n",
      "BRUTUS\n",
      "SECOND PLEBEIAN\n",
      "FIRST PLEBEIAN\n",
      "BRUTUS\n",
      " more to Caesar than you shall do to ...\n",
      "\n",
      "==================================================\n",
      "Question: What role does Cassius play in the conspiracy?\n",
      "\n",
      "Answer: Cassius appears to be a key figure in the conspiracy against Caesar. He is mentioned as the one who \"first did whet\" the speaker (likely Brutus) \"against Caesar\" (Page 31), indicating that Cassius played a role in persuading or influencing Brutus to join the conspiracy. Additionally, Cassius is shown to be involved in the planning and execution of the conspiracy, as he is present when Popilius Lena wishes them success in their \"enterprise\" (Page 51) and is concerned that their purpose may be discovered. However, the exact nature and extent of Cassius' role in the conspiracy are not fully detailed in the provided context.\n",
      "\n",
      "Top source:\n",
      "[Page 31]:\n",
      "Go to the gate; somebody knocks. Since Cassius first did whet me against Caesar,\n",
      " I have not slept. Between the acting of a dreadful thing\n",
      " And the first motion, all the interim is\n",
      " Like a phantasma o...\n",
      "\n",
      "Results exported to ../RAG Results/multiquery_rag_results.txt\n",
      "\n",
      "Answer: Cassius appears to be a key figure in the conspiracy against Caesar. He is mentioned as the one who \"first did whet\" the speaker (likely Brutus) \"against Caesar\" (Page 31), indicating that Cassius played a role in persuading or influencing Brutus to join the conspiracy. Additionally, Cassius is shown to be involved in the planning and execution of the conspiracy, as he is present when Popilius Lena wishes them success in their \"enterprise\" (Page 51) and is concerned that their purpose may be discovered. However, the exact nature and extent of Cassius' role in the conspiracy are not fully detailed in the provided context.\n",
      "\n",
      "Top source:\n",
      "[Page 31]:\n",
      "Go to the gate; somebody knocks. Since Cassius first did whet me against Caesar,\n",
      " I have not slept. Between the acting of a dreadful thing\n",
      " And the first motion, all the interim is\n",
      " Like a phantasma o...\n",
      "\n",
      "Results exported to ../RAG Results/multiquery_rag_results.txt\n"
     ]
    }
   ],
   "source": [
    "# Test with multiple questions to evaluate system\n",
    "results_for_export = []\n",
    "\n",
    "test_questions = [\n",
    "    \"What are the main themes in Julius Caesar?\",\n",
    "    \"How does Brutus justify killing Caesar?\",\n",
    "    \"What role does Cassius play in the conspiracy?\"\n",
    "]\n",
    "\n",
    "for question in test_questions:\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(f\"Question: {question}\")\n",
    "    response = answer_with_hybrid_rag(question)\n",
    "    print(f\"\\nAnswer: {response['answer']}\")\n",
    "    print(\"\\nTop source:\")\n",
    "    if len(response[\"source_documents\"][\"documents\"][0]) > 0:\n",
    "        top_doc = response[\"source_documents\"][\"documents\"][0][0]\n",
    "        top_meta = response[\"source_documents\"][\"metadatas\"][0][0]\n",
    "        page = top_meta.get(\"page_number\", \"N/A\")\n",
    "        print(f\"[Page {page}]:\\n{top_doc[:200]}...\")  # Print first 200 chars\n",
    "        # Save for export\n",
    "        results_for_export.append({\n",
    "            \"question\": question,\n",
    "            \"answer\": response['answer'],\n",
    "            \"page\": page,\n",
    "            \"chunk\": top_doc\n",
    "        })\n",
    "    else:\n",
    "        print(\"No sources found.\")\n",
    "        results_for_export.append({\n",
    "            \"question\": question,\n",
    "            \"answer\": response['answer'],\n",
    "            \"page\": None,\n",
    "            \"chunk\": None\n",
    "        })\n",
    "\n",
    "# Export results to a well-formatted text file\n",
    "with open(multiquery_rag_output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"RAG Multi-Query Evaluation Results\\n\")\n",
    "    f.write(\"=\"*60 + \"\\n\\n\")\n",
    "    for idx, res in enumerate(results_for_export, 1):\n",
    "        f.write(f\"Question {idx}: {res['question']}\\n\")\n",
    "        f.write(f\"Answer:\\n{res['answer']}\\n\\n\")\n",
    "        if res[\"chunk\"]:\n",
    "            f.write(f\"Top Source Chunk (Page {res['page']}):\\n{res['chunk']}\\n\")\n",
    "        else:\n",
    "            f.write(\"Top Source Chunk: No sources found.\\n\")\n",
    "        f.write(\"-\"*60 + \"\\n\\n\")\n",
    "print(f\"\\nResults exported to {multiquery_rag_output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "742c3905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install datasets ragas -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c56031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exists: True\n",
      "Size: 3530 bytes\n",
      "First few characters:\n",
      " [\n",
      "    {\n",
      "        \"question\": \"How does Caesar first enter the play?\",\n",
      "        \"ideal_answer\": \"In a triumphal procession; he has defeated the sons of his deceased rival, Pompey\"\n",
      "    },\n",
      "{\n",
      "\"question\": \"W\n",
      "[INFO] Loaded 25 QA pairs from testbed.\n",
      "[INFO] Found cached answers at '../RAG Results/cached_rag_answers.json'\n",
      "[INFO] Loading 25 cached answers (skipping generation)\n",
      "[INFO] Created dataset with 25 samples\n",
      "\n",
      "[INFO] Starting RAGAS evaluation with llama-3.3-70b-versatile...\n",
      "[INFO] Rate limits: 30 RPM | 12K TPM | Using 2.5s delays\n",
      "[INFO] Estimated time: ~1.0 minutes\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f18585e54ef84340b141460df3aad4cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[ERROR] Failed (attempt 3): Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k9ys8bswepfshkmm14afrk4c` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99917, Requested 466. Please try again in 5m30.912s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "[ERROR] Failed (attempt 3): Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k9ys8bswepfshkmm14afrk4c` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99917, Requested 487. Please try again in 5m49.056s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "[ERROR] Failed (attempt 3): Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k9ys8bswepfshkmm14afrk4c` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99917, Requested 408. Please try again in 4m40.8s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "[ERROR] Failed (attempt 3): Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k9ys8bswepfshkmm14afrk4c` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99917, Requested 396. Please try again in 4m30.432s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "[ERROR] Failed (attempt 3): Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k9ys8bswepfshkmm14afrk4c` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99917, Requested 396. Please try again in 4m30.432s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "[ERROR] Failed (attempt 3): Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k9ys8bswepfshkmm14afrk4c` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99917, Requested 411. Please try again in 4m43.392s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "[ERROR] Failed (attempt 3): Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k9ys8bswepfshkmm14afrk4c` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99917, Requested 385. Please try again in 4m20.928s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "[ERROR] Failed (attempt 3): Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k9ys8bswepfshkmm14afrk4c` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99917, Requested 501. Please try again in 6m1.152s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "[ERROR] Failed (attempt 3): Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k9ys8bswepfshkmm14afrk4c` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99917, Requested 634. Please try again in 7m56.064s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "[ERROR] Failed (attempt 3): Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k9ys8bswepfshkmm14afrk4c` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99917, Requested 455. Please try again in 5m21.408s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "[ERROR] Failed (attempt 3): Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k9ys8bswepfshkmm14afrk4c` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99917, Requested 476. Please try again in 5m39.552s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "[ERROR] Failed (attempt 3): Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k9ys8bswepfshkmm14afrk4c` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99917, Requested 475. Please try again in 5m38.688s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "[ERROR] Failed (attempt 3): Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k9ys8bswepfshkmm14afrk4c` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99917, Requested 383. Please try again in 4m19.2s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "[ERROR] Failed (attempt 3): Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k9ys8bswepfshkmm14afrk4c` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99917, Requested 648. Please try again in 8m8.159999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "[ERROR] Failed (attempt 3): Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k9ys8bswepfshkmm14afrk4c` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99917, Requested 419. Please try again in 4m50.304s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "[ERROR] Failed (attempt 3): Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k9ys8bswepfshkmm14afrk4c` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99917, Requested 466. Please try again in 5m30.912s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "[ERROR] Failed (attempt 3): Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k9ys8bswepfshkmm14afrk4c` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99917, Requested 487. Please try again in 5m49.056s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "[ERROR] Failed (attempt 3): Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k9ys8bswepfshkmm14afrk4c` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99917, Requested 408. Please try again in 4m40.8s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "[ERROR] Failed (attempt 3): Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k9ys8bswepfshkmm14afrk4c` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99917, Requested 396. Please try again in 4m30.432s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "[ERROR] Failed (attempt 3): Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k9ys8bswepfshkmm14afrk4c` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99917, Requested 396. Please try again in 4m30.432s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "[ERROR] Failed (attempt 3): Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k9ys8bswepfshkmm14afrk4c` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99917, Requested 411. Please try again in 4m43.392s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "[ERROR] Failed (attempt 3): Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k9ys8bswepfshkmm14afrk4c` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99917, Requested 385. Please try again in 4m20.928s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "[ERROR] Failed (attempt 3): Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k9ys8bswepfshkmm14afrk4c` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99917, Requested 501. Please try again in 6m1.152s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "[ERROR] Failed (attempt 3): Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k9ys8bswepfshkmm14afrk4c` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99917, Requested 634. Please try again in 7m56.064s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "[ERROR] Failed (attempt 3): Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k9ys8bswepfshkmm14afrk4c` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99917, Requested 455. Please try again in 5m21.408s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "[ERROR] Failed (attempt 3): Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k9ys8bswepfshkmm14afrk4c` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99917, Requested 476. Please try again in 5m39.552s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "[ERROR] Failed (attempt 3): Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k9ys8bswepfshkmm14afrk4c` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99917, Requested 475. Please try again in 5m38.688s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "[ERROR] Failed (attempt 3): Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k9ys8bswepfshkmm14afrk4c` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99917, Requested 383. Please try again in 4m19.2s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "[ERROR] Failed (attempt 3): Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k9ys8bswepfshkmm14afrk4c` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99917, Requested 648. Please try again in 8m8.159999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "[ERROR] Failed (attempt 3): Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k9ys8bswepfshkmm14afrk4c` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99917, Requested 419. Please try again in 4m50.304s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[ERROR] Failed (attempt 3): Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k9ys8bswepfshkmm14afrk4c` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99913, Requested 1733. Please try again in 23m42.144s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "[ERROR] Failed (attempt 3): Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k9ys8bswepfshkmm14afrk4c` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99913, Requested 1733. Please try again in 23m42.144s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[ERROR] Failed (attempt 3): Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k9ys8bswepfshkmm14afrk4c` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99894, Requested 466. Please try again in 5m11.039999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "[ERROR] Failed (attempt 3): Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k9ys8bswepfshkmm14afrk4c` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99894, Requested 408. Please try again in 4m20.928s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "[ERROR] Failed (attempt 3): Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k9ys8bswepfshkmm14afrk4c` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99894, Requested 634. Please try again in 7m36.192s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "[ERROR] Failed (attempt 3): Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k9ys8bswepfshkmm14afrk4c` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99894, Requested 707. Please try again in 8m39.264s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "[ERROR] Failed (attempt 3): Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k9ys8bswepfshkmm14afrk4c` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99894, Requested 411. Please try again in 4m23.52s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "[ERROR] Failed (attempt 3): Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k9ys8bswepfshkmm14afrk4c` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99894, Requested 784. Please try again in 9m45.791999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "[ERROR] Failed (attempt 3): Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k9ys8bswepfshkmm14afrk4c` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99894, Requested 487. Please try again in 5m29.184s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "[ERROR] Failed (attempt 3): Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k9ys8bswepfshkmm14afrk4c` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99894, Requested 385. Please try again in 4m1.055999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "[ERROR] Failed (attempt 3): Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k9ys8bswepfshkmm14afrk4c` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99894, Requested 466. Please try again in 5m11.039999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "[ERROR] Failed (attempt 3): Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k9ys8bswepfshkmm14afrk4c` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99894, Requested 408. Please try again in 4m20.928s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "[ERROR] Failed (attempt 3): Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k9ys8bswepfshkmm14afrk4c` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99894, Requested 634. Please try again in 7m36.192s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "[ERROR] Failed (attempt 3): Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k9ys8bswepfshkmm14afrk4c` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99894, Requested 707. Please try again in 8m39.264s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "[ERROR] Failed (attempt 3): Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k9ys8bswepfshkmm14afrk4c` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99894, Requested 411. Please try again in 4m23.52s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "[ERROR] Failed (attempt 3): Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k9ys8bswepfshkmm14afrk4c` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99894, Requested 784. Please try again in 9m45.791999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "[ERROR] Failed (attempt 3): Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k9ys8bswepfshkmm14afrk4c` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99894, Requested 487. Please try again in 5m29.184s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "[ERROR] Failed (attempt 3): Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k9ys8bswepfshkmm14afrk4c` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99894, Requested 385. Please try again in 4m1.055999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "[ERROR] Failed (attempt 3): Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k9ys8bswepfshkmm14afrk4c` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99893, Requested 820. Please try again in 10m16.032s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "[ERROR] Failed (attempt 3): Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k9ys8bswepfshkmm14afrk4c` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99893, Requested 965. Please try again in 12m21.312s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "[ERROR] Failed (attempt 3): Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k9ys8bswepfshkmm14afrk4c` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99893, Requested 383. Please try again in 3m58.464s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "[ERROR] Failed (attempt 3): Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k9ys8bswepfshkmm14afrk4c` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99893, Requested 729. Please try again in 8m57.408s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "[ERROR] Failed (attempt 3): Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k9ys8bswepfshkmm14afrk4c` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99893, Requested 705. Please try again in 8m36.672s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "[ERROR] Failed (attempt 3): Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k9ys8bswepfshkmm14afrk4c` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99893, Requested 787. Please try again in 9m47.52s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "[ERROR] Failed (attempt 3): Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k9ys8bswepfshkmm14afrk4c` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99893, Requested 455. Please try again in 5m0.672s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "[ERROR] Failed (attempt 3): Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k9ys8bswepfshkmm14afrk4c` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99893, Requested 820. Please try again in 10m16.032s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "[ERROR] Failed (attempt 3): Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k9ys8bswepfshkmm14afrk4c` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99893, Requested 965. Please try again in 12m21.312s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "[ERROR] Failed (attempt 3): Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k9ys8bswepfshkmm14afrk4c` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99893, Requested 383. Please try again in 3m58.464s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "[ERROR] Failed (attempt 3): Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k9ys8bswepfshkmm14afrk4c` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99893, Requested 729. Please try again in 8m57.408s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "[ERROR] Failed (attempt 3): Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k9ys8bswepfshkmm14afrk4c` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99893, Requested 705. Please try again in 8m36.672s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "[ERROR] Failed (attempt 3): Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k9ys8bswepfshkmm14afrk4c` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99893, Requested 787. Please try again in 9m47.52s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "[ERROR] Failed (attempt 3): Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k9ys8bswepfshkmm14afrk4c` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99893, Requested 455. Please try again in 5m0.672s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 333\u001b[0m\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[INFO] Estimated time: ~\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(dataset)\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39mREQUEST_DELAY\u001b[38;5;250m \u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m60\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m minutes\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    331\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m--> 333\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    334\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    335\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mfaithfulness\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43manswer_relevancy\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    336\u001b[0m \u001b[43m    \u001b[49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    337\u001b[0m \u001b[43m    \u001b[49m\u001b[43membeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membeddings\u001b[49m\n\u001b[0;32m    338\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m    340\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m    341\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m end_time \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[1;32mc:\\Users\\micro\\Anaconda3\\envs\\NLP_2\\Lib\\site-packages\\ragas\\_analytics.py:277\u001b[0m, in \u001b[0;36mtrack_was_completed.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    274\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[0;32m    275\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs: P\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: P\u001b[38;5;241m.\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[0;32m    276\u001b[0m     track(IsCompleteEvent(event_type\u001b[38;5;241m=\u001b[39mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, is_completed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m))\n\u001b[1;32m--> 277\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    278\u001b[0m     track(IsCompleteEvent(event_type\u001b[38;5;241m=\u001b[39mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, is_completed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[0;32m    280\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\micro\\Anaconda3\\envs\\NLP_2\\Lib\\site-packages\\ragas\\evaluation.py:461\u001b[0m, in \u001b[0;36mevaluate\u001b[1;34m(dataset, metrics, llm, embeddings, experiment_name, callbacks, run_config, token_usage_parser, raise_exceptions, column_map, show_progress, batch_size, _run_id, _pbar, return_executor, allow_nest_asyncio)\u001b[0m\n\u001b[0;32m    457\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    458\u001b[0m     \u001b[38;5;66;03m# Default behavior: use nest_asyncio for backward compatibility (Jupyter notebooks)\u001b[39;00m\n\u001b[0;32m    459\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mragas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01masync_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m run\n\u001b[1;32m--> 461\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_async_wrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\micro\\Anaconda3\\envs\\NLP_2\\Lib\\site-packages\\ragas\\async_utils.py:156\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(async_func, allow_nest_asyncio)\u001b[0m\n\u001b[0;32m    148\u001b[0m     loop_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(loop)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n\u001b[0;32m    149\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    150\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot execute nested async code with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloop_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    151\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muvloop does not support nested event loop execution. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    152\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease use asyncio\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms standard event loop in Jupyter environments, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    153\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor refactor your code to avoid nested async calls.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    154\u001b[0m     )\n\u001b[1;32m--> 156\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43masyncio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcoro\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\micro\\Anaconda3\\envs\\NLP_2\\Lib\\site-packages\\nest_asyncio.py:30\u001b[0m, in \u001b[0;36m_patch_asyncio.<locals>.run\u001b[1;34m(main, debug)\u001b[0m\n\u001b[0;32m     28\u001b[0m task \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(main)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 30\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m task\u001b[38;5;241m.\u001b[39mdone():\n",
      "File \u001b[1;32mc:\\Users\\micro\\Anaconda3\\envs\\NLP_2\\Lib\\site-packages\\nest_asyncio.py:92\u001b[0m, in \u001b[0;36m_patch_loop.<locals>.run_until_complete\u001b[1;34m(self, future)\u001b[0m\n\u001b[0;32m     90\u001b[0m     f\u001b[38;5;241m.\u001b[39m_log_destroy_pending \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m f\u001b[38;5;241m.\u001b[39mdone():\n\u001b[1;32m---> 92\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     93\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stopping:\n\u001b[0;32m     94\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\micro\\Anaconda3\\envs\\NLP_2\\Lib\\site-packages\\nest_asyncio.py:115\u001b[0m, in \u001b[0;36m_patch_loop.<locals>._run_once\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    108\u001b[0m     heappop(scheduled)\n\u001b[0;32m    110\u001b[0m timeout \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    111\u001b[0m     \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ready \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stopping\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mmin\u001b[39m(\u001b[38;5;28mmax\u001b[39m(\n\u001b[0;32m    113\u001b[0m         scheduled[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_when \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime(), \u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m86400\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m scheduled\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m--> 115\u001b[0m event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_events(event_list)\n\u001b[0;32m    118\u001b[0m end_time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clock_resolution\n",
      "File \u001b[1;32mc:\\Users\\micro\\Anaconda3\\envs\\NLP_2\\Lib\\selectors.py:323\u001b[0m, in \u001b[0;36mSelectSelector.select\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    321\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    322\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 323\u001b[0m     r, w, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_select\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_readers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_writers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    324\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[0;32m    325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "File \u001b[1;32mc:\\Users\\micro\\Anaconda3\\envs\\NLP_2\\Lib\\selectors.py:314\u001b[0m, in \u001b[0;36mSelectSelector._select\u001b[1;34m(self, r, w, _, timeout)\u001b[0m\n\u001b[0;32m    313\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_select\u001b[39m(\u001b[38;5;28mself\u001b[39m, r, w, _, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 314\u001b[0m     r, w, x \u001b[38;5;241m=\u001b[39m select\u001b[38;5;241m.\u001b[39mselect(r, w, w, timeout)\n\u001b[0;32m    315\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m r, w \u001b[38;5;241m+\u001b[39m x, []\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] Failed (attempt 3): Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k9ys8bswepfshkmm14afrk4c` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99888, Requested 2188. Please try again in 29m53.664s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] Failed (attempt 3): Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k9ys8bswepfshkmm14afrk4c` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99870, Requested 466. Please try again in 4m50.304s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "[ERROR] Failed (attempt 3): Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k9ys8bswepfshkmm14afrk4c` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99870, Requested 408. Please try again in 4m0.191999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "[ERROR] Failed (attempt 3): Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k9ys8bswepfshkmm14afrk4c` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99870, Requested 411. Please try again in 4m2.784s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "[ERROR] Failed (attempt 3): Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k9ys8bswepfshkmm14afrk4c` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99870, Requested 634. Please try again in 7m15.456s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] Failed (attempt 3): Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k9ys8bswepfshkmm14afrk4c` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99870, Requested 1069. Please try again in 13m31.296s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "[ERROR] Failed (attempt 3): Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k9ys8bswepfshkmm14afrk4c` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99870, Requested 487. Please try again in 5m8.448s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "[ERROR] Failed (attempt 3): Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k9ys8bswepfshkmm14afrk4c` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99870, Requested 385. Please try again in 3m40.32s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "[ERROR] Failed (attempt 3): Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k9ys8bswepfshkmm14afrk4c` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99870, Requested 1146. Please try again in 14m37.824s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "[ERROR] Failed (attempt 3): Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k9ys8bswepfshkmm14afrk4c` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99870, Requested 1091. Please try again in 13m50.304s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "[ERROR] Failed (attempt 3): Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k9ys8bswepfshkmm14afrk4c` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99870, Requested 1149. Please try again in 14m40.416s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "[ERROR] Failed (attempt 3): Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k9ys8bswepfshkmm14afrk4c` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99870, Requested 1183. Please try again in 15m9.791999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] Failed (attempt 3): Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k9ys8bswepfshkmm14afrk4c` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99870, Requested 1065. Please try again in 13m27.84s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "[ERROR] Failed (attempt 3): Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k9ys8bswepfshkmm14afrk4c` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99870, Requested 383. Please try again in 3m38.592s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "[ERROR] Failed (attempt 3): Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k9ys8bswepfshkmm14afrk4c` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99870, Requested 1325. Please try again in 17m12.48s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "[ERROR] Failed (attempt 3): Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k9ys8bswepfshkmm14afrk4c` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99870, Requested 455. Please try again in 4m40.8s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[ERROR] Failed (attempt 3): Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k9ys8bswepfshkmm14afrk4c` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99865, Requested 2692. Please try again in 36m49.248s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "[ERROR] Failed (attempt 3): Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k9ys8bswepfshkmm14afrk4c` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99865, Requested 2692. Please try again in 36m49.248s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] Failed (attempt 3): Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k9ys8bswepfshkmm14afrk4c` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99847, Requested 710. Please try again in 8m1.248s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "[ERROR] Failed (attempt 3): Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k9ys8bswepfshkmm14afrk4c` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99847, Requested 769. Please try again in 8m52.223999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "[ERROR] Failed (attempt 3): Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k9ys8bswepfshkmm14afrk4c` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99847, Requested 1483. Please try again in 19m9.12s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt statement_generator_prompt failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt statement_generator_prompt failed to parse output: The output parser failed to parse the output including retries.\n",
      "Exception raised in Job[6]: RagasOutputParserException(The output parser failed to parse the output including retries.)\n",
      "Exception raised in Job[6]: RagasOutputParserException(The output parser failed to parse the output including retries.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] Failed (attempt 3): Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k9ys8bswepfshkmm14afrk4c` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99847, Requested 712. Please try again in 8m2.976s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "[ERROR] Failed (attempt 3): Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k9ys8bswepfshkmm14afrk4c` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99846, Requested 798. Please try again in 9m16.416s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "[ERROR] Failed (attempt 3): Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k9ys8bswepfshkmm14afrk4c` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99846, Requested 941. Please try again in 11m19.968s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "[ERROR] Failed (attempt 3): Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k9ys8bswepfshkmm14afrk4c` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99846, Requested 1534. Please try again in 19m52.32s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt statement_generator_prompt failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt statement_generator_prompt failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt statement_generator_prompt failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt statement_generator_prompt failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt statement_generator_prompt failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt statement_generator_prompt failed to parse output: The output parser failed to parse the output including retries.\n",
      "Exception raised in Job[14]: RagasOutputParserException(The output parser failed to parse the output including retries.)\n",
      "Exception raised in Job[14]: RagasOutputParserException(The output parser failed to parse the output including retries.)\n",
      "Exception raised in Job[16]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[16]: AssertionError(LLM is not set)\n",
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt statement_generator_prompt failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt statement_generator_prompt failed to parse output: The output parser failed to parse the output including retries.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] Failed (attempt 3): Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k9ys8bswepfshkmm14afrk4c` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99846, Requested 686. Please try again in 7m39.648s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "[ERROR] Failed (attempt 3): Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k9ys8bswepfshkmm14afrk4c` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99846, Requested 1541. Please try again in 19m58.368s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "[ERROR] Failed (attempt 3): Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k9ys8bswepfshkmm14afrk4c` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99846, Requested 1461. Please try again in 18m49.248s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "[ERROR] Failed (attempt 3): Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k9ys8bswepfshkmm14afrk4c` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99846, Requested 1586. Please try again in 20m37.248s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "[ERROR] Failed (attempt 3): Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k9ys8bswepfshkmm14afrk4c` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99846, Requested 1453. Please try again in 18m42.336s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt statement_generator_prompt failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt statement_generator_prompt failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt statement_generator_prompt failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt statement_generator_prompt failed to parse output: The output parser failed to parse the output including retries.\n",
      "Exception raised in Job[0]: RagasOutputParserException(The output parser failed to parse the output including retries.)\n",
      "Exception raised in Job[0]: RagasOutputParserException(The output parser failed to parse the output including retries.)\n",
      "Exception raised in Job[2]: RagasOutputParserException(The output parser failed to parse the output including retries.)\n",
      "Exception raised in Job[2]: RagasOutputParserException(The output parser failed to parse the output including retries.)\n",
      "Exception raised in Job[10]: RagasOutputParserException(The output parser failed to parse the output including retries.)\n",
      "Exception raised in Job[10]: RagasOutputParserException(The output parser failed to parse the output including retries.)\n",
      "Exception raised in Job[4]: RagasOutputParserException(The output parser failed to parse the output including retries.)\n",
      "Exception raised in Job[4]: RagasOutputParserException(The output parser failed to parse the output including retries.)\n",
      "Exception raised in Job[12]: RagasOutputParserException(The output parser failed to parse the output including retries.)\n",
      "Exception raised in Job[12]: RagasOutputParserException(The output parser failed to parse the output including retries.)\n",
      "Exception raised in Job[17]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[17]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[18]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[18]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[19]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[19]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[20]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[20]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[21]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[21]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[22]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[22]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[23]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[23]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[24]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[24]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[25]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[25]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[26]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[26]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[27]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[27]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[28]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[28]: AssertionError(LLM is not set)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] Failed (attempt 3): Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k9ys8bswepfshkmm14afrk4c` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99846, Requested 1719. Please try again in 22m32.16s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "[ERROR] Failed (attempt 3): Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k9ys8bswepfshkmm14afrk4c` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99846, Requested 756. Please try again in 8m40.128s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "[ERROR] Failed (attempt 3): Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k9ys8bswepfshkmm14afrk4c` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99846, Requested 686. Please try again in 7m39.648s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception raised in Job[29]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[30]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[30]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[31]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[31]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[32]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[32]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[33]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[33]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[34]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[34]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[35]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[35]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[36]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[36]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[37]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[37]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[38]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[38]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[39]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[39]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[40]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[40]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[41]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[41]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[42]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[42]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[43]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[43]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[44]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[44]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[45]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[45]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[46]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[46]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[47]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[47]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[48]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[48]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[49]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[49]: AssertionError(LLM is not set)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt n_l_i_statement_prompt failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt n_l_i_statement_prompt failed to parse output: The output parser failed to parse the output including retries.\n",
      "Exception raised in Job[8]: RagasOutputParserException(The output parser failed to parse the output including retries.)\n",
      "Exception raised in Job[8]: RagasOutputParserException(The output parser failed to parse the output including retries.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] Failed (attempt 3): Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k9ys8bswepfshkmm14afrk4c` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99841, Requested 3278. Please try again in 44m54.816s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[ERROR] Failed (attempt 3): Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k9ys8bswepfshkmm14afrk4c` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99823, Requested 1080. Please try again in 13m0.192s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "[ERROR] Failed (attempt 3): Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k9ys8bswepfshkmm14afrk4c` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99823, Requested 1141. Please try again in 13m52.896s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "[ERROR] Failed (attempt 3): Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k9ys8bswepfshkmm14afrk4c` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99823, Requested 1080. Please try again in 13m0.192s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "[ERROR] Failed (attempt 3): Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k9ys8bswepfshkmm14afrk4c` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99823, Requested 1080. Please try again in 13m0.192s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "[ERROR] Failed (attempt 3): Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k9ys8bswepfshkmm14afrk4c` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99823, Requested 1141. Please try again in 13m52.896s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "[ERROR] Failed (attempt 3): Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k9ys8bswepfshkmm14afrk4c` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99823, Requested 1080. Please try again in 13m0.192s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "[ERROR] Failed (attempt 3): Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k9ys8bswepfshkmm14afrk4c` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99823, Requested 1169. Please try again in 14m17.088s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "[ERROR] Failed (attempt 3): Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k9ys8bswepfshkmm14afrk4c` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99823, Requested 1309. Please try again in 16m18.048s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "[ERROR] Failed (attempt 3): Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k9ys8bswepfshkmm14afrk4c` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99823, Requested 1054. Please try again in 12m37.728s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "[ERROR] Failed (attempt 3): Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k9ys8bswepfshkmm14afrk4c` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99823, Requested 1169. Please try again in 14m17.088s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "[ERROR] Failed (attempt 3): Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k9ys8bswepfshkmm14afrk4c` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99823, Requested 1309. Please try again in 16m18.048s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "[ERROR] Failed (attempt 3): Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k9ys8bswepfshkmm14afrk4c` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99823, Requested 1054. Please try again in 12m37.728s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "[ERROR] Failed (attempt 3): Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k9ys8bswepfshkmm14afrk4c` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99822, Requested 1124. Please try again in 13m37.343999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "[ERROR] Failed (attempt 3): Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k9ys8bswepfshkmm14afrk4c` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99822, Requested 1056. Please try again in 12m38.592s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "[ERROR] Failed (attempt 3): Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k9ys8bswepfshkmm14afrk4c` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99822, Requested 1124. Please try again in 13m37.343999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "[ERROR] Failed (attempt 3): Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k9ys8bswepfshkmm14afrk4c` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99822, Requested 1056. Please try again in 12m38.592s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 5.0s (attempt 1)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n",
      "[WARN] Rate limit hit. Waiting 7.5s (attempt 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt response_relevance_prompt failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt response_relevance_prompt failed to parse output: The output parser failed to parse the output including retries.\n",
      "Exception raised in Job[7]: RagasOutputParserException(The output parser failed to parse the output including retries.)\n",
      "Exception raised in Job[7]: RagasOutputParserException(The output parser failed to parse the output including retries.)\n",
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt response_relevance_prompt failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt response_relevance_prompt failed to parse output: The output parser failed to parse the output including retries.\n",
      "Exception raised in Job[1]: RagasOutputParserException(The output parser failed to parse the output including retries.)\n",
      "Exception raised in Job[1]: RagasOutputParserException(The output parser failed to parse the output including retries.)\n",
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt response_relevance_prompt failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt response_relevance_prompt failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt response_relevance_prompt failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt response_relevance_prompt failed to parse output: The output parser failed to parse the output including retries.\n",
      "Exception raised in Job[11]: RagasOutputParserException(The output parser failed to parse the output including retries.)\n",
      "Exception raised in Job[11]: RagasOutputParserException(The output parser failed to parse the output including retries.)\n",
      "Exception raised in Job[9]: RagasOutputParserException(The output parser failed to parse the output including retries.)\n",
      "Exception raised in Job[9]: RagasOutputParserException(The output parser failed to parse the output including retries.)\n",
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] Failed (attempt 3): Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k9ys8bswepfshkmm14afrk4c` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99800, Requested 1478. Please try again in 18m24.192s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "[ERROR] Failed (attempt 3): Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k9ys8bswepfshkmm14afrk4c` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99800, Requested 1539. Please try again in 19m16.896s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "[ERROR] Failed (attempt 3): Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k9ys8bswepfshkmm14afrk4c` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99800, Requested 1576. Please try again in 19m48.864s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "[ERROR] Failed (attempt 3): Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k9ys8bswepfshkmm14afrk4c` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99800, Requested 1474. Please try again in 18m20.735999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "[ERROR] Failed (attempt 3): Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k9ys8bswepfshkmm14afrk4c` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99799, Requested 1709. Please try again in 21m42.912s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt response_relevance_prompt failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt response_relevance_prompt failed to parse output: The output parser failed to parse the output including retries.\n",
      "Exception raised in Job[13]: RagasOutputParserException(The output parser failed to parse the output including retries.)\n",
      "Exception raised in Job[13]: RagasOutputParserException(The output parser failed to parse the output including retries.)\n",
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt response_relevance_prompt failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt response_relevance_prompt failed to parse output: The output parser failed to parse the output including retries.\n",
      "Exception raised in Job[5]: RagasOutputParserException(The output parser failed to parse the output including retries.)\n",
      "Exception raised in Job[5]: RagasOutputParserException(The output parser failed to parse the output including retries.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] Failed (attempt 3): Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k9ys8bswepfshkmm14afrk4c` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99799, Requested 1448. Please try again in 17m57.408s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt response_relevance_prompt failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt response_relevance_prompt failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt response_relevance_prompt failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt response_relevance_prompt failed to parse output: The output parser failed to parse the output including retries.\n",
      "Exception raised in Job[3]: RagasOutputParserException(The output parser failed to parse the output including retries.)\n",
      "Exception raised in Job[3]: RagasOutputParserException(The output parser failed to parse the output including retries.)\n",
      "Exception raised in Job[15]: RagasOutputParserException(The output parser failed to parse the output including retries.)\n",
      "Exception raised in Job[15]: RagasOutputParserException(The output parser failed to parse the output including retries.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] Failed (attempt 3): Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k9ys8bswepfshkmm14afrk4c` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99799, Requested 1454. Please try again in 18m2.591999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "[ERROR] Failed (attempt 3): Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k9ys8bswepfshkmm14afrk4c` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99799, Requested 1520. Please try again in 18m59.616s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    }
   ],
   "source": [
    "# === Groq + RAG + RAGAS Evaluation ===\n",
    "# Prereqs:\n",
    "# pip install ragas datasets groq tqdm sentence-transformers numpy\n",
    "\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import time\n",
    "import asyncio\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from datasets import Dataset\n",
    "from groq import Groq\n",
    "\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import faithfulness, answer_relevancy\n",
    "from ragas.embeddings.base import HuggingfaceEmbeddings\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain_core.prompt_values import PromptValue\n",
    "from langchain_core.outputs import Generation, LLMResult\n",
    "\n",
    "\n",
    "# ==== CONFIG ====\n",
    "# Use the API key already set in previous cell\n",
    "groq_client = Groq(api_key=os.environ[\"GROQ_API_KEY\"])\n",
    "\n",
    "testbed_path = \"../RAG Results/test_bed.json\"\n",
    "output_metrics_path = \"../RAG Results/multiquery_rag_metrics.txt\"\n",
    "cached_answers_path = \"../RAG Results/cached_rag_answers.json\"  # NEW: Cache file\n",
    "TOP_K = 3\n",
    "\n",
    "GROQ_RAG_MODEL = \"llama-3.3-70b-versatile\"\n",
    "GROQ_RAGAS_MODEL = \"llama-3.3-70b-versatile\"\n",
    "EMBED_MODEL = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "\n",
    "# Rate limiting config for llama-3.3-70b-versatile:\n",
    "# RPM: 30 (requests per minute)\n",
    "# RPD: 1,000 (requests per day)\n",
    "# TPM: 12,000 (tokens per minute)\n",
    "# TPD: 100,000 (tokens per day)\n",
    "REQUEST_DELAY = 2.5  # seconds between requests (allows ~24 RPM, safe margin below 30 RPM)\n",
    "BATCH_SIZE = 5  # Process in small batches to avoid hitting token limits\n",
    "MAX_RETRIES = 3  # Retry failed requests\n",
    "\n",
    "print(\"Exists:\", os.path.exists(testbed_path))\n",
    "print(\"Size:\", os.path.getsize(testbed_path), \"bytes\")\n",
    "\n",
    "with open(testbed_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    first_200 = f.read(200)\n",
    "print(\"First few characters:\\n\", first_200)\n",
    "\n",
    "\n",
    "# ==== 1️⃣ Load test data ====\n",
    "with open(testbed_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    test_data = json.load(f)\n",
    "\n",
    "print(f\"[INFO] Loaded {len(test_data)} QA pairs from testbed.\")\n",
    "\n",
    "\n",
    "# ==== 2️⃣ Groq generation with retry logic ====\n",
    "def generate_with_groq(prompt, model_name=GROQ_RAG_MODEL, retries=MAX_RETRIES):\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            chat_completion = groq_client.chat.completions.create(\n",
    "                messages=[\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": prompt,\n",
    "                    }\n",
    "                ],\n",
    "                model=model_name,\n",
    "                temperature=0.7,\n",
    "            )\n",
    "            time.sleep(REQUEST_DELAY)\n",
    "            return chat_completion.choices[0].message.content.strip()\n",
    "        except Exception as e:\n",
    "            if \"rate_limit\" in str(e).lower():\n",
    "                wait_time = REQUEST_DELAY * (attempt + 2)  # Exponential backoff\n",
    "                print(f\"[WARN] Rate limit hit. Waiting {wait_time}s before retry {attempt + 1}/{retries}\")\n",
    "                time.sleep(wait_time)\n",
    "            else:\n",
    "                print(f\"[ERROR] Groq API call failed (attempt {attempt + 1}): {e}\")\n",
    "                if attempt == retries - 1:\n",
    "                    time.sleep(REQUEST_DELAY)\n",
    "                    return None\n",
    "                time.sleep(REQUEST_DELAY)\n",
    "    return None\n",
    "\n",
    "\n",
    "# ==== 3️⃣ Groq wrapper for RAGAS following BaseRagasLLM interface ====\n",
    "from ragas.llms.base import BaseRagasLLM as RagasBaseLLM\n",
    "from ragas.run_config import RunConfig\n",
    "\n",
    "class GroqRagasLLM(RagasBaseLLM):\n",
    "    \"\"\"Groq LLM wrapper implementing RAGAS BaseRagasLLM interface.\"\"\"\n",
    "    \n",
    "    def __init__(self, model_name):\n",
    "        super().__init__(run_config=RunConfig())\n",
    "        self.model_name = model_name\n",
    "        self.client = Groq(api_key=os.environ[\"GROQ_API_KEY\"])\n",
    "        self.request_count = 0\n",
    "        self.last_request_time = time.time()\n",
    "\n",
    "    def _rate_limit_check(self):\n",
    "        \"\"\"Ensure we don't exceed rate limits\"\"\"\n",
    "        current_time = time.time()\n",
    "        time_since_last = current_time - self.last_request_time\n",
    "        \n",
    "        # Ensure minimum delay between requests\n",
    "        if time_since_last < REQUEST_DELAY:\n",
    "            sleep_time = REQUEST_DELAY - time_since_last\n",
    "            time.sleep(sleep_time)\n",
    "        \n",
    "        self.last_request_time = time.time()\n",
    "        self.request_count += 1\n",
    "\n",
    "    def _extract_text_from_prompt(self, prompt: PromptValue) -> str:\n",
    "        \"\"\"Extract text from PromptValue object.\"\"\"\n",
    "        # PromptValue has .to_string() method\n",
    "        if hasattr(prompt, \"to_string\"):\n",
    "            return prompt.to_string()\n",
    "        # Fallback to string conversion\n",
    "        return str(prompt)\n",
    "\n",
    "    def generate_text(\n",
    "        self,\n",
    "        prompt: PromptValue,\n",
    "        n: int = 1,\n",
    "        temperature: float = 0.01,\n",
    "        stop=None,\n",
    "        callbacks=None,\n",
    "    ) -> LLMResult:\n",
    "        \"\"\"Synchronous generation - required by BaseRagasLLM.\"\"\"\n",
    "        prompt_text = self._extract_text_from_prompt(prompt)\n",
    "        generations = []\n",
    "        \n",
    "        for i in range(n):\n",
    "            for attempt in range(MAX_RETRIES):\n",
    "                try:\n",
    "                    # Rate limit check\n",
    "                    self._rate_limit_check()\n",
    "                    \n",
    "                    chat_completion = self.client.chat.completions.create(\n",
    "                        messages=[{\"role\": \"user\", \"content\": prompt_text}],\n",
    "                        model=self.model_name,\n",
    "                        temperature=temperature,\n",
    "                    )\n",
    "                    \n",
    "                    text = chat_completion.choices[0].message.content.strip()\n",
    "                    generations.append([Generation(text=text)])\n",
    "                    break  # Success\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    if \"rate_limit\" in str(e).lower() and attempt < MAX_RETRIES - 1:\n",
    "                        wait_time = REQUEST_DELAY * (attempt + 2)\n",
    "                        print(f\"[WARN] Rate limit hit. Waiting {wait_time}s (attempt {attempt + 1})\")\n",
    "                        time.sleep(wait_time)\n",
    "                    else:\n",
    "                        print(f\"[ERROR] Failed (attempt {attempt + 1}): {e}\")\n",
    "                        if attempt == MAX_RETRIES - 1:\n",
    "                            generations.append([Generation(text=f\"[Error: {e}]\")])\n",
    "                        else:\n",
    "                            time.sleep(REQUEST_DELAY)\n",
    "        \n",
    "        return LLMResult(generations=generations)\n",
    "\n",
    "    async def agenerate_text(\n",
    "        self,\n",
    "        prompt: PromptValue,\n",
    "        n: int = 1,\n",
    "        temperature: float = 0.01,\n",
    "        stop=None,\n",
    "        callbacks=None,\n",
    "    ) -> LLMResult:\n",
    "        \"\"\"Asynchronous generation - required by BaseRagasLLM.\"\"\"\n",
    "        prompt_text = self._extract_text_from_prompt(prompt)\n",
    "        generations = []\n",
    "        \n",
    "        for i in range(n):\n",
    "            for attempt in range(MAX_RETRIES):\n",
    "                try:\n",
    "                    # Rate limit check\n",
    "                    await asyncio.sleep(REQUEST_DELAY)\n",
    "                    \n",
    "                    # Run blocking SDK call in thread\n",
    "                    chat_completion = await asyncio.to_thread(\n",
    "                        self.client.chat.completions.create,\n",
    "                        messages=[{\"role\": \"user\", \"content\": prompt_text}],\n",
    "                        model=self.model_name,\n",
    "                        temperature=temperature,\n",
    "                    )\n",
    "                    \n",
    "                    text = chat_completion.choices[0].message.content.strip()\n",
    "                    generations.append([Generation(text=text)])\n",
    "                    break  # Success\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    if \"rate_limit\" in str(e).lower() and attempt < MAX_RETRIES - 1:\n",
    "                        wait_time = REQUEST_DELAY * (attempt + 2)\n",
    "                        print(f\"[WARN] Rate limit hit. Waiting {wait_time}s (attempt {attempt + 1})\")\n",
    "                        await asyncio.sleep(wait_time)\n",
    "                    else:\n",
    "                        print(f\"[ERROR] Failed (attempt {attempt + 1}): {e}\")\n",
    "                        if attempt == MAX_RETRIES - 1:\n",
    "                            generations.append([Generation(text=f\"[Error: {e}]\")])\n",
    "                        else:\n",
    "                            await asyncio.sleep(REQUEST_DELAY)\n",
    "        \n",
    "        return LLMResult(generations=generations)\n",
    "\n",
    "    def is_finished(self, response: LLMResult) -> bool:\n",
    "        \"\"\"Check if response is complete - required by BaseRagasLLM.\"\"\"\n",
    "        return True\n",
    "\n",
    "\n",
    "# ==== 4️⃣ Check collection availability ====\n",
    "try:\n",
    "    collection.query(query_texts=[\"test\"], n_results=1)\n",
    "except NameError:\n",
    "    print(\"\\n[CRITICAL WARNING] The 'collection' object (ChromaDB) is NOT defined.\")\n",
    "    print(\"Please initialize your ChromaDB client/collection before running this cell.\")\n",
    "    raise SystemExit\n",
    "\n",
    "\n",
    "# ==== 5️⃣ Generate records with caching and rate limiting ====\n",
    "records = []\n",
    "\n",
    "# Check if cached answers exist\n",
    "if os.path.exists(cached_answers_path):\n",
    "    print(f\"[INFO] Found cached answers at '{cached_answers_path}'\")\n",
    "    try:\n",
    "        with open(cached_answers_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            cached_data = json.load(f)\n",
    "        \n",
    "        # Validate cache matches current test data\n",
    "        if len(cached_data) == len(test_data):\n",
    "            questions_match = all(\n",
    "                cached_data[i][\"question\"] == test_data[i][\"question\"] \n",
    "                for i in range(len(test_data))\n",
    "            )\n",
    "            \n",
    "            if questions_match:\n",
    "                print(f\"[INFO] Loading {len(cached_data)} cached answers (skipping generation)\")\n",
    "                records = cached_data\n",
    "            else:\n",
    "                print(\"[WARN] Cached questions don't match test data. Regenerating...\")\n",
    "        else:\n",
    "            print(f\"[WARN] Cache size mismatch ({len(cached_data)} vs {len(test_data)}). Regenerating...\")\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Failed to load cache: {e}. Regenerating...\")\n",
    "\n",
    "# Generate new answers if cache not usable\n",
    "if not records:\n",
    "    print(f\"[INFO] Generating RAG answers with rate limiting (max 30 RPM)...\")\n",
    "    print(f\"[INFO] Request delay: {REQUEST_DELAY}s | Batch size: {BATCH_SIZE}\")\n",
    "    \n",
    "    for item in tqdm(test_data, desc=\"Generating Groq RAG answers\"):\n",
    "        question = item[\"question\"]\n",
    "        ideal_answer = item[\"ideal_answer\"]\n",
    "\n",
    "        retrieved = collection.query(query_texts=[question], n_results=TOP_K)\n",
    "        retrieved_docs = retrieved[\"documents\"][0]\n",
    "        retrieved_context = \"\\n\".join(retrieved_docs)\n",
    "\n",
    "        prompt = (\n",
    "            f\"Context:\\n{retrieved_context}\\n\\n\"\n",
    "            f\"Question:\\n{question}\\n\\nAnswer:\"\n",
    "        )\n",
    "\n",
    "        generated_answer = generate_with_groq(prompt)\n",
    "        if not generated_answer:\n",
    "            generated_answer = f\"[Fallback mock answer] Context excerpt: {retrieved_docs[0][:150]}...\"\n",
    "\n",
    "        records.append({\n",
    "            \"question\": question,\n",
    "            \"contexts\": retrieved_docs,\n",
    "            \"answer\": generated_answer,\n",
    "            \"ground_truth\": ideal_answer,\n",
    "        })\n",
    "        \n",
    "        # Progress update every 5 questions\n",
    "        if len(records) % 5 == 0:\n",
    "            print(f\"[INFO] Processed {len(records)}/{len(test_data)} questions\")\n",
    "    \n",
    "    # Save generated answers to cache\n",
    "    try:\n",
    "        os.makedirs(os.path.dirname(cached_answers_path), exist_ok=True)\n",
    "        with open(cached_answers_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(records, f, indent=2, ensure_ascii=False)\n",
    "        print(f\"[SUCCESS] Cached {len(records)} answers to '{cached_answers_path}'\")\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] Failed to save cache: {e}\")\n",
    "\n",
    "\n",
    "# ==== 6️⃣ Convert to HF Dataset ====\n",
    "dataset = Dataset.from_list(records)\n",
    "print(f\"[INFO] Created dataset with {len(dataset)} samples\")\n",
    "\n",
    "\n",
    "# ==== 7️⃣ Custom HuggingFace Embedding Wrapper ====\n",
    "class CustomHuggingfaceEmbeddings(HuggingfaceEmbeddings):\n",
    "    \"\"\"Implements both sync + async embedding methods for latest RAGAS.\"\"\"\n",
    "    def __init__(self, model_name: str):\n",
    "        # ✅ Do not call super()\n",
    "        self.model_name = model_name\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "\n",
    "    # --- Sync methods ---\n",
    "    def embed_documents(self, texts):\n",
    "        return self.model.encode(texts, show_progress_bar=False).tolist()\n",
    "\n",
    "    def embed_query(self, text):\n",
    "        return self.model.encode([text], show_progress_bar=False).tolist()[0]\n",
    "\n",
    "    # --- Async methods ---\n",
    "    async def aembed_documents(self, texts):\n",
    "        return self.embed_documents(texts)\n",
    "\n",
    "    async def aembed_query(self, text):\n",
    "        return self.embed_query(text)\n",
    "\n",
    "\n",
    "# ==== 8️⃣ Evaluate with RAGAS ====\n",
    "llm = GroqRagasLLM(GROQ_RAGAS_MODEL)\n",
    "embeddings = CustomHuggingfaceEmbeddings(model_name=EMBED_MODEL)\n",
    "\n",
    "print(f\"\\n[INFO] Starting RAGAS evaluation with {GROQ_RAGAS_MODEL}...\")\n",
    "print(f\"[INFO] Rate limits: 30 RPM | 12K TPM | Using {REQUEST_DELAY}s delays\")\n",
    "print(f\"[INFO] Estimated time: ~{len(dataset) * REQUEST_DELAY / 60:.1f} minutes\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "results = evaluate(\n",
    "    dataset=dataset,\n",
    "    metrics=[faithfulness, answer_relevancy],\n",
    "    llm=llm,\n",
    "    embeddings=embeddings\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(f\"\\n[SUCCESS] Evaluation completed in {elapsed_time / 60:.2f} minutes\")\n",
    "\n",
    "\n",
    "# ==== 9️⃣ Save Results ====\n",
    "faithfulness_scores = results[\"faithfulness\"]\n",
    "answer_relevancy_scores = results[\"answer_relevancy\"]\n",
    "\n",
    "# ✅ Compute mean values\n",
    "faithfulness_mean = float(np.mean(faithfulness_scores))\n",
    "answer_relevancy_mean = float(np.mean(answer_relevancy_scores))\n",
    "\n",
    "os.makedirs(os.path.dirname(output_metrics_path), exist_ok=True)\n",
    "\n",
    "with open(output_metrics_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"=== RAG Evaluation Metrics (Groq + RAGAS) ===\\n\")\n",
    "    f.write(f\"Timestamp: {datetime.now()}\\n\")\n",
    "    f.write(f\"Evaluation Duration: {elapsed_time / 60:.2f} minutes\\n\\n\")\n",
    "    f.write(f\"RAG Generation Model: {GROQ_RAG_MODEL}\\n\")\n",
    "    f.write(f\"RAGAS Evaluation Model: {GROQ_RAGAS_MODEL}\\n\")\n",
    "    f.write(f\"Rate Limiting: {REQUEST_DELAY}s delay between requests\\n\")\n",
    "    f.write(f\"Cached Answers: {os.path.basename(cached_answers_path)}\\n\\n\")\n",
    "    f.write(f\"Faithfulness (avg): {faithfulness_mean:.4f}\\n\")\n",
    "    f.write(f\"Answer Relevancy (avg): {answer_relevancy_mean:.4f}\\n\\n\")\n",
    "    f.write(\"Full Results:\\n\")\n",
    "    f.write(str(results))\n",
    "\n",
    "print(f\"\\n✅ Evaluation complete! Metrics saved to '{output_metrics_path}'\")\n",
    "print(f\"Faithfulness (avg): {faithfulness_mean:.4f} | Answer Relevancy (avg): {answer_relevancy_mean:.4f}\")\n",
    "print(f\"\\n[TIP] To regenerate answers, delete: {cached_answers_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
