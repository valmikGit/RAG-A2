{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd26bf01",
   "metadata": {},
   "source": [
    "### Imports and Path setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0d607ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import chromadb\n",
    "import pickle\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "multiquery_rag_output_path = \"../RAG Results/multiquery_rag_results.txt\"\n",
    "Relative_Database_path = \"./chroma_Data_v4\"\n",
    "Absolute_Database_path = Path(Relative_Database_path).resolve()\n",
    "file_path = \"../Chunking/Chunk_files/julius-caesar_chunks_semantic.pkl\"\n",
    "# Create a new collection with a unique name\n",
    "collection_name = \"anlp_rag_collection\"\n",
    "# # Set API key\n",
    "# os.environ[\"GOOGLE_API_KEY\"] = os.environ.get(\"GEMINI_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3b927c",
   "metadata": {},
   "source": [
    "### Chroma Setup and Chunk Loading\n",
    "Sets up persistant client and loads previously computed chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b9b8be6",
   "metadata": {},
   "outputs": [
    {
     "ename": "PanicException",
     "evalue": "range start index 10 out of range for slice of length 9",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPanicException\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Initialize the persistent client\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m client \u001b[38;5;241m=\u001b[39m \u001b[43mchromadb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPersistentClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mAbsolute_Database_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[INFO] ChromaDB client initialized at: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mAbsolute_Database_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# List existing collections\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\micro\\Anaconda3\\envs\\NLP_2\\Lib\\site-packages\\chromadb\\__init__.py:167\u001b[0m, in \u001b[0;36mPersistentClient\u001b[1;34m(path, settings, tenant, database)\u001b[0m\n\u001b[0;32m    164\u001b[0m tenant \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(tenant)\n\u001b[0;32m    165\u001b[0m database \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(database)\n\u001b[1;32m--> 167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mClientCreator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtenant\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtenant\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatabase\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatabase\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msettings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msettings\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\micro\\Anaconda3\\envs\\NLP_2\\Lib\\site-packages\\chromadb\\api\\client.py:65\u001b[0m, in \u001b[0;36mClient.__init__\u001b[1;34m(self, tenant, database, settings)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m     61\u001b[0m     tenant: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m DEFAULT_TENANT,\n\u001b[0;32m     62\u001b[0m     database: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m DEFAULT_DATABASE,\n\u001b[0;32m     63\u001b[0m     settings: Settings \u001b[38;5;241m=\u001b[39m Settings(),\n\u001b[0;32m     64\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msettings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msettings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tenant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     67\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtenant \u001b[38;5;241m=\u001b[39m tenant\n",
      "File \u001b[1;32mc:\\Users\\micro\\Anaconda3\\envs\\NLP_2\\Lib\\site-packages\\chromadb\\api\\shared_system_client.py:19\u001b[0m, in \u001b[0;36mSharedSystemClient.__init__\u001b[1;34m(self, settings)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m     16\u001b[0m     settings: Settings \u001b[38;5;241m=\u001b[39m Settings(),\n\u001b[0;32m     17\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_identifier \u001b[38;5;241m=\u001b[39m SharedSystemClient\u001b[38;5;241m.\u001b[39m_get_identifier_from_settings(settings)\n\u001b[1;32m---> 19\u001b[0m     \u001b[43mSharedSystemClient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_system_if_not_exists\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_identifier\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msettings\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\micro\\Anaconda3\\envs\\NLP_2\\Lib\\site-packages\\chromadb\\api\\shared_system_client.py:32\u001b[0m, in \u001b[0;36mSharedSystemClient._create_system_if_not_exists\u001b[1;34m(cls, identifier, settings)\u001b[0m\n\u001b[0;32m     29\u001b[0m     new_system\u001b[38;5;241m.\u001b[39minstance(ProductTelemetryClient)\n\u001b[0;32m     30\u001b[0m     new_system\u001b[38;5;241m.\u001b[39minstance(ServerAPI)\n\u001b[1;32m---> 32\u001b[0m     \u001b[43mnew_system\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     34\u001b[0m     previous_system \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_identifier_to_system[identifier]\n",
      "File \u001b[1;32mc:\\Users\\micro\\Anaconda3\\envs\\NLP_2\\Lib\\site-packages\\chromadb\\config.py:471\u001b[0m, in \u001b[0;36mSystem.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    469\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mstart()\n\u001b[0;32m    470\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m component \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcomponents():\n\u001b[1;32m--> 471\u001b[0m     \u001b[43mcomponent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\micro\\Anaconda3\\envs\\NLP_2\\Lib\\site-packages\\chromadb\\api\\rust.py:112\u001b[0m, in \u001b[0;36mRustBindingsAPI.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    101\u001b[0m migration_mode_bindings \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    102\u001b[0m     chromadb_rust_bindings\u001b[38;5;241m.\u001b[39mMigrationMode\u001b[38;5;241m.\u001b[39mApply\n\u001b[0;32m    103\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m migration_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    104\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m chromadb_rust_bindings\u001b[38;5;241m.\u001b[39mMigrationMode\u001b[38;5;241m.\u001b[39mValidate\n\u001b[0;32m    105\u001b[0m )\n\u001b[0;32m    106\u001b[0m sqlite_config \u001b[38;5;241m=\u001b[39m chromadb_rust_bindings\u001b[38;5;241m.\u001b[39mSqliteDBConfig(\n\u001b[0;32m    107\u001b[0m     hash_type\u001b[38;5;241m=\u001b[39mhash_type_bindings,\n\u001b[0;32m    108\u001b[0m     migration_mode\u001b[38;5;241m=\u001b[39mmigration_mode_bindings,\n\u001b[0;32m    109\u001b[0m     url\u001b[38;5;241m=\u001b[39msqlite_persist_path,\n\u001b[0;32m    110\u001b[0m )\n\u001b[1;32m--> 112\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbindings \u001b[38;5;241m=\u001b[39m \u001b[43mchromadb_rust_bindings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBindings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    113\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_reset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_system\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msettings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow_reset\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    114\u001b[0m \u001b[43m    \u001b[49m\u001b[43msqlite_db_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msqlite_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    115\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpersist_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpersist_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    116\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhnsw_cache_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhnsw_cache_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    117\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mPanicException\u001b[0m: range start index 10 out of range for slice of length 9"
     ]
    }
   ],
   "source": [
    "# Initialize the persistent client\n",
    "client = chromadb.PersistentClient(path=Absolute_Database_path)\n",
    "print(f\"[INFO] ChromaDB client initialized at: {Absolute_Database_path}\")\n",
    "\n",
    "# List existing collections\n",
    "existing_collections = client.list_collections()\n",
    "print(f\"Existing collections: {[c.name for c in existing_collections]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788e6272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded 126 chunks from '../Chunking/Chunk_files/julius-caesar_chunks_semantic.pkl'.\n",
      "\n",
      "Verification:\n",
      "✓ Total chunks loaded: 126\n",
      "✓ First chunk preview: Michael Witmore\n",
      "Director, Folger Shakespeare Library\n",
      "It is hard to imagine a world without Shakespea...\n",
      "✓ Metadata: {'source': '../julius-caesar_PDF_FolgerShakespeare.pdf', 'page_number': 3, 'c': 'semantic', 'ischunk': True}\n"
     ]
    }
   ],
   "source": [
    "# Load chunks with version compatibility handling\n",
    "\n",
    "loaded_docs = []\n",
    "\n",
    "try:\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        # Try loading normally first\n",
    "        try:\n",
    "            loaded_docs = pickle.load(f)\n",
    "            print(f\"Successfully loaded {len(loaded_docs)} chunks from '{file_path}'.\")\n",
    "        except AttributeError as e:\n",
    "            # Handle Pydantic v1 vs v2 incompatibility\n",
    "            if \"__fields_set__\" in str(e):\n",
    "                print(\"[WARN] Pickle file has version incompatibility. Attempting to reconstruct...\")\n",
    "                \n",
    "                # Reopen and load with custom unpickler\n",
    "                f.seek(0)\n",
    "                import pickle\n",
    "                \n",
    "                # Create a custom unpickler to handle missing attributes\n",
    "                class CompatibilityUnpickler(pickle.Unpickler):\n",
    "                    def find_class(self, module, name):\n",
    "                        # Map old LangChain classes to current ones\n",
    "                        if 'langchain' in module and 'schema' in module:\n",
    "                            # Import current Document class\n",
    "                            from langchain.schema import Document\n",
    "                            if name == 'Document':\n",
    "                                return Document\n",
    "                        return super().find_class(module, name)\n",
    "                \n",
    "                loaded_docs = CompatibilityUnpickler(f).load()\n",
    "                \n",
    "                # Reconstruct documents if needed\n",
    "                from langchain.schema import Document\n",
    "                reconstructed_docs = []\n",
    "                for doc in loaded_docs:\n",
    "                    if hasattr(doc, 'page_content') and hasattr(doc, 'metadata'):\n",
    "                        # Create fresh Document object\n",
    "                        new_doc = Document(\n",
    "                            page_content=doc.page_content,\n",
    "                            metadata=doc.metadata if isinstance(doc.metadata, dict) else {}\n",
    "                        )\n",
    "                        reconstructed_docs.append(new_doc)\n",
    "                    else:\n",
    "                        reconstructed_docs.append(doc)\n",
    "                \n",
    "                loaded_docs = reconstructed_docs\n",
    "                print(f\"[SUCCESS] Reconstructed {len(loaded_docs)} chunks successfully.\")\n",
    "            else:\n",
    "                raise\n",
    "                \n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file '{file_path}' was not found.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading file: {e}\")\n",
    "    print(f\"Error type: {type(e).__name__}\")\n",
    "    \n",
    "    # Last resort: regenerate the chunks\n",
    "    print(\"\\n[TIP] If error persists, regenerate the chunks using First_chunking_attempt.ipynb\")\n",
    "\n",
    "# Verify loaded documents\n",
    "print(\"\\nVerification:\")\n",
    "if loaded_docs:\n",
    "    print(f\"✓ Total chunks loaded: {len(loaded_docs)}\")\n",
    "    print(f\"✓ First chunk preview: {loaded_docs[0].page_content[:100]}...\")\n",
    "    print(f\"✓ Metadata: {loaded_docs[0].metadata}\")\n",
    "else:\n",
    "    print(\"✗ No documents loaded. Please regenerate chunks.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5cbb00",
   "metadata": {},
   "source": [
    "### Set up Embedding Function\n",
    "Will use default SentenceTransformer for generating embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928a1da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding function initialized with model: all-MiniLM-L6-v2\n"
     ]
    }
   ],
   "source": [
    "# Install if needed\n",
    "# !pip install sentence_transformers\n",
    "\n",
    "# Set up embedding function\n",
    "from chromadb.utils.embedding_functions import SentenceTransformerEmbeddingFunction\n",
    "embedding_function = SentenceTransformerEmbeddingFunction(model_name=\"all-MiniLM-L6-v2\")\n",
    "print(\"Embedding function initialized with model: all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e9f44b",
   "metadata": {},
   "source": [
    "### Creating new Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b34eceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Deleted existing collection 'anlp_rag_collection'\n",
      "[SUCCESS] Fresh collection 'anlp_rag_collection' created successfully\n",
      "Current count in collection: 0\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# FORCE DELETE the collection if it exists\n",
    "try:\n",
    "    client.delete_collection(name=collection_name)\n",
    "    print(f\"[INFO] Deleted existing collection '{collection_name}'\")\n",
    "except Exception as e:\n",
    "    print(f\"[INFO] No existing collection named '{collection_name}' to delete.\")\n",
    "\n",
    "# Create a FRESH collection\n",
    "collection = client.create_collection(\n",
    "    name=collection_name,\n",
    "    embedding_function=embedding_function,\n",
    "    metadata={\n",
    "        \"description\": \"Julius Caesar Chunks collection for RAG\",\n",
    "        \"created\": str(datetime.now())\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f\"[SUCCESS] Fresh collection '{collection_name}' created successfully\")\n",
    "print(f\"Current count in collection: {collection.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b449ba",
   "metadata": {},
   "source": [
    "### Add data to collection\n",
    "The chunks have to be given an id and added to the collection now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa83664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Generating IDs with prefix: julius-caesar\n",
      "[INFO] Prepared 126 documents with IDs like: julius-caesar_chunk_0, julius-caesar_chunk_1...\n",
      "[INFO] Added batch: 0 to 125 (126 documents)\n",
      "\n",
      "[SUCCESS] Added 126 documents to collection 'anlp_rag_collection'\n",
      "[INFO] All chunks have IDs in format: julius-caesar_chunk_<number>\n",
      "[INFO] Added batch: 0 to 125 (126 documents)\n",
      "\n",
      "[SUCCESS] Added 126 documents to collection 'anlp_rag_collection'\n",
      "[INFO] All chunks have IDs in format: julius-caesar_chunk_<number>\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "import hashlib\n",
    "\n",
    "# Extract document name from file path for ID generation\n",
    "# This will give us \"julius-caesar\" from the file path\n",
    "doc_name = file_path.split('/')[-1].split('_chunks')[0]\n",
    "\n",
    "# Prepare documents for ChromaDB\n",
    "ids = []\n",
    "documents = []\n",
    "metadatas = []\n",
    "\n",
    "print(f\"[INFO] Generating IDs with prefix: {doc_name}\")\n",
    "\n",
    "# Process each loaded document chunk\n",
    "for i, doc in enumerate(loaded_docs):\n",
    "    # Generate a deterministic ID based on document name and index\n",
    "    # This ensures all chunks from the same document have consistent IDs\n",
    "    doc_id = f\"{doc_name}_chunk_{i}\"\n",
    "    \n",
    "    # Get the document text\n",
    "    document_text = doc.page_content\n",
    "    \n",
    "    # Get the document metadata\n",
    "    metadata = doc.metadata\n",
    "    \n",
    "    # Add to our lists\n",
    "    ids.append(doc_id)\n",
    "    documents.append(document_text)\n",
    "    metadatas.append(metadata)\n",
    "\n",
    "print(f\"[INFO] Prepared {len(ids)} documents with IDs like: {ids[0]}, {ids[1] if len(ids) > 1 else 'N/A'}...\")\n",
    "\n",
    "# Add documents in batches to avoid memory issues\n",
    "batch_size = 500\n",
    "total_added = 0\n",
    "\n",
    "for i in range(0, len(ids), batch_size):\n",
    "    end_idx = min(i + batch_size, len(ids))\n",
    "    \n",
    "    # Simply add all documents (collection is fresh, no need to update)\n",
    "    collection.add(\n",
    "        ids=ids[i:end_idx],\n",
    "        documents=documents[i:end_idx],\n",
    "        metadatas=metadatas[i:end_idx]\n",
    "    )\n",
    "    \n",
    "    total_added += end_idx - i\n",
    "    print(f\"[INFO] Added batch: {i} to {end_idx-1} ({end_idx-i} documents)\")\n",
    "\n",
    "print(f\"\\n[SUCCESS] Added {total_added} documents to collection '{collection_name}'\")\n",
    "print(f\"[INFO] All chunks have IDs in format: {doc_name}_chunk_<number>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fd6408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total documents in collection: 126\n",
      "\n",
      "Sample entries:\n",
      "\n",
      "--- Document 1 ---\n",
      "ID: julius-caesar_chunk_0\n",
      "Text: Michael Witmore\n",
      "Director, Folger Shakespeare Library\n",
      "It is hard to imagine a world without Shakespea...\n",
      "Metadata: {'source': '../julius-caesar_PDF_FolgerShakespeare.pdf', 'page_number': 3, 'ischunk': True, 'c': 'semantic'}\n",
      "\n",
      "--- Document 2 ---\n",
      "ID: julius-caesar_chunk_1\n",
      "Text: Until now, with the release of The Folger Shakespeare (formerly\n",
      "Folger Digital Texts), readers in se...\n",
      "Metadata: {'source': '../julius-caesar_PDF_FolgerShakespeare.pdf', 'c': 'semantic', 'page_number': 4, 'ischunk': True}\n",
      "\n",
      "--- Document 3 ---\n",
      "ID: julius-caesar_chunk_2\n",
      "Text: At\n",
      "any point in the text, you can hover your cursor over a bracket for\n",
      "more information. Because the...\n",
      "Metadata: {'c': 'semantic', 'page_number': 5, 'source': '../julius-caesar_PDF_FolgerShakespeare.pdf', 'ischunk': True}\n"
     ]
    }
   ],
   "source": [
    "# Check collection count\n",
    "count = collection.count()\n",
    "print(f\"Total documents in collection: {count}\")\n",
    "\n",
    "# Peek at the first few entries\n",
    "peek = collection.peek(limit=3)\n",
    "print(\"\\nSample entries:\")\n",
    "for i, (doc_id, doc_text, metadata) in enumerate(zip(\n",
    "    peek['ids'], peek['documents'], peek['metadatas']\n",
    ")):\n",
    "    print(f\"\\n--- Document {i+1} ---\")\n",
    "    print(f\"ID: {doc_id}\")\n",
    "    print(f\"Text: {doc_text[:100]}...\")\n",
    "    print(f\"Metadata: {metadata}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc47242",
   "metadata": {},
   "source": [
    "### Querying the Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ee0a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rich table for displaying results (optional but nice)\n",
    "try:\n",
    "    from rich.console import Console\n",
    "    from rich.table import Table\n",
    "    \n",
    "    console = Console()\n",
    "    use_rich = True\n",
    "except ImportError:\n",
    "    use_rich = False\n",
    "    print(\"Rich package not found. Using standard print.\")\n",
    "\n",
    "# Function to display query results\n",
    "def print_results(results, use_rich=use_rich):\n",
    "    if use_rich:\n",
    "        table = Table(show_header=True, header_style=\"bold magenta\")\n",
    "        table.add_column(\"Rank\", width=6)\n",
    "        table.add_column(\"Document ID\")\n",
    "        table.add_column(\"Document Text\", width=60)\n",
    "        table.add_column(\"Page\")\n",
    "        table.add_column(\"Distance\")\n",
    "        \n",
    "        docs = results['documents'][0]\n",
    "        ids = results['ids'][0]\n",
    "        metas = results['metadatas'][0]\n",
    "        distances = results['distances'][0]\n",
    "        \n",
    "        for i, (doc, doc_id, meta, dist) in enumerate(zip(docs, ids, metas, distances)):\n",
    "            table.add_row(\n",
    "                str(i+1),\n",
    "                doc_id,\n",
    "                (doc[:100] + \"...\") if len(doc) > 100 else doc,\n",
    "                str(meta.get('page_number', 'N/A')),\n",
    "                f\"{dist:.4f}\"\n",
    "            )\n",
    "        \n",
    "        console.print(table)\n",
    "    else:\n",
    "        # Standard print version\n",
    "        for i, (doc, meta, dist) in enumerate(zip(\n",
    "            results['documents'][0], \n",
    "            results['metadatas'][0], \n",
    "            results['distances'][0]\n",
    "        )):\n",
    "            print(f\"\\n--- Result {i+1} ---\")\n",
    "            print(f\"Text: {doc[:100]}...\")\n",
    "            print(f\"Metadata: {meta}\")\n",
    "            print(f\"Distance: {dist:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac82c7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for query: 'What themes are explored in Julius Caesar?'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━┳━━━━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Rank   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Document ID           </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Document Text                                                </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Page </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Distance </span>┃\n",
       "┡━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━╇━━━━━━━━━━┩\n",
       "│ 1      │ julius-caesar_chunk_… │ 95                                                           │ 51   │ 0.3517   │\n",
       "│        │                       │ Julius Caesar                                                │      │          │\n",
       "│        │                       │ ACT 3. SC. 1                                                 │      │          │\n",
       "│        │                       │ POPILIUS                                                     │      │          │\n",
       "│        │                       │ CASSIUS                                                      │      │          │\n",
       "│        │                       │ POPILIUS                                                     │      │          │\n",
       "│        │                       │ He walks away. BRUTUS                                        │      │          │\n",
       "│        │                       │ CASSIUS                                                      │      │          │\n",
       "│        │                       │ BRUTUS                                                       │      │          │\n",
       "│        │                       │ CASSIUS...                                                   │      │          │\n",
       "│ 2      │ julius-caesar_chunk_… │ CAESAR                                                       │ 50   │ 0.3766   │\n",
       "│        │                       │ SOOTHSAYER                                                   │      │          │\n",
       "│        │                       │ ARTEMIDORUS                                                  │      │          │\n",
       "│        │                       │ DECIUS                                                       │      │          │\n",
       "│        │                       │ ARTEMIDORUS                                                  │      │          │\n",
       "│        │                       │ CAESAR                                                       │      │          │\n",
       "│        │                       │ ARTEMIDORUS                                                  │      │          │\n",
       "│        │                       │ CAESAR                                                       │      │          │\n",
       "│        │                       │ PUBLIUS                                                      │      │          │\n",
       "│        │                       │ CASSIUS                                                      │      │          │\n",
       "│        │                       │ Caesar go...                                                 │      │          │\n",
       "│ 3      │ julius-caesar_chunk_… │ 85                                                           │ 47   │ 0.3788   │\n",
       "│        │                       │ Julius Caesar                                                │      │          │\n",
       "│        │                       │ ACT 2. SC. 4                                                 │      │          │\n",
       "│        │                       │ ARTEMIDORUS                                                  │      │          │\n",
       "│        │                       │  Thy lover,                                                  │      │          │\n",
       "│        │                       │  Artemidorus                                                 │      │          │\n",
       "│        │                       │ He exits. PORTIA                                             │      │          │\n",
       "│        │                       │ LUCIUS                                                       │      │          │\n",
       "│        │                       │ PORTIA                                                       │      │          │\n",
       "│        │                       │ En...                                                        │      │          │\n",
       "└────────┴───────────────────────┴──────────────────────────────────────────────────────────────┴──────┴──────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━┳━━━━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35mRank  \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mDocument ID          \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mDocument Text                                               \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mPage\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mDistance\u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━╇━━━━━━━━━━┩\n",
       "│ 1      │ julius-caesar_chunk_… │ 95                                                           │ 51   │ 0.3517   │\n",
       "│        │                       │ Julius Caesar                                                │      │          │\n",
       "│        │                       │ ACT 3. SC. 1                                                 │      │          │\n",
       "│        │                       │ POPILIUS                                                     │      │          │\n",
       "│        │                       │ CASSIUS                                                      │      │          │\n",
       "│        │                       │ POPILIUS                                                     │      │          │\n",
       "│        │                       │ He walks away. BRUTUS                                        │      │          │\n",
       "│        │                       │ CASSIUS                                                      │      │          │\n",
       "│        │                       │ BRUTUS                                                       │      │          │\n",
       "│        │                       │ CASSIUS...                                                   │      │          │\n",
       "│ 2      │ julius-caesar_chunk_… │ CAESAR                                                       │ 50   │ 0.3766   │\n",
       "│        │                       │ SOOTHSAYER                                                   │      │          │\n",
       "│        │                       │ ARTEMIDORUS                                                  │      │          │\n",
       "│        │                       │ DECIUS                                                       │      │          │\n",
       "│        │                       │ ARTEMIDORUS                                                  │      │          │\n",
       "│        │                       │ CAESAR                                                       │      │          │\n",
       "│        │                       │ ARTEMIDORUS                                                  │      │          │\n",
       "│        │                       │ CAESAR                                                       │      │          │\n",
       "│        │                       │ PUBLIUS                                                      │      │          │\n",
       "│        │                       │ CASSIUS                                                      │      │          │\n",
       "│        │                       │ Caesar go...                                                 │      │          │\n",
       "│ 3      │ julius-caesar_chunk_… │ 85                                                           │ 47   │ 0.3788   │\n",
       "│        │                       │ Julius Caesar                                                │      │          │\n",
       "│        │                       │ ACT 2. SC. 4                                                 │      │          │\n",
       "│        │                       │ ARTEMIDORUS                                                  │      │          │\n",
       "│        │                       │  Thy lover,                                                  │      │          │\n",
       "│        │                       │  Artemidorus                                                 │      │          │\n",
       "│        │                       │ He exits. PORTIA                                             │      │          │\n",
       "│        │                       │ LUCIUS                                                       │      │          │\n",
       "│        │                       │ PORTIA                                                       │      │          │\n",
       "│        │                       │ En...                                                        │      │          │\n",
       "└────────┴───────────────────────┴──────────────────────────────────────────────────────────────┴──────┴──────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run a sample query\n",
    "query = \"What themes are explored in Julius Caesar?\"\n",
    "results = collection.query(\n",
    "    query_texts=[query],\n",
    "    n_results=3,\n",
    "    include=[\"documents\", \"metadatas\", \"distances\"]\n",
    ")\n",
    "\n",
    "print(f\"\\nResults for query: '{query}'\")\n",
    "print_results(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb314ce",
   "metadata": {},
   "source": [
    "### Natural Language Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbc9b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install groq --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497764f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix version conflicts - downgrade to compatible versions\n",
    "# !pip uninstall langchain-groq -y\n",
    "# !pip install \"langchain-core<0.3.0\" --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e7f9b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groq LLM initialized with model: llama-3.3-70b-versatile (using native Groq SDK)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from groq import Groq\n",
    "\n",
    "# Set the API key for Groq\n",
    "os.environ[\"GROQ_API_KEY\"] = \"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\"\n",
    "\n",
    "# Initialize Groq client\n",
    "groq_client = Groq(api_key=os.environ[\"GROQ_API_KEY\"])\n",
    "\n",
    "# Create a simple LLM wrapper that works like LangChain's ChatGroq\n",
    "class GroqLLM:\n",
    "    def __init__(self, model, temperature=0.7):\n",
    "        self.model = model\n",
    "        self.temperature = temperature\n",
    "        self.client = groq_client\n",
    "    \n",
    "    def invoke(self, prompt):\n",
    "        \"\"\"Invoke the LLM with a prompt and return response\"\"\"\n",
    "        # Handle both string prompts and LangChain PromptValue objects\n",
    "        if hasattr(prompt, 'to_string'):\n",
    "            prompt_text = prompt.to_string()\n",
    "        elif hasattr(prompt, 'text'):\n",
    "            prompt_text = prompt.text\n",
    "        else:\n",
    "            prompt_text = str(prompt)\n",
    "        \n",
    "        response = self.client.chat.completions.create(\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt_text}],\n",
    "            model=self.model,\n",
    "            temperature=self.temperature\n",
    "        )\n",
    "        \n",
    "        # Return an object with .content attribute for compatibility\n",
    "        class Response:\n",
    "            def __init__(self, content):\n",
    "                self.content = content\n",
    "            def __str__(self):\n",
    "                return self.content\n",
    "        \n",
    "        return Response(response.choices[0].message.content)\n",
    "\n",
    "# Initialize our custom LLM wrapper\n",
    "llm = GroqLLM(\n",
    "    model=\"llama-3.3-70b-versatile\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "print(\"Groq LLM initialized with model: llama-3.3-70b-versatile (using native Groq SDK)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab6b7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# Better prompt template for Julius Caesar\n",
    "rag_prompt_template = \"\"\"\n",
    "You are an expert on Shakespeare's Julius Caesar. Answer questions using ONLY the context below.\n",
    "If you can't find a complete answer in the context but see partial information, try to provide what you can find and acknowledge the limitations of the available information.\n",
    "If there is NO relevant information at all in the context, respond with \"I don't have enough information to answer this question.\"\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {query}\n",
    "\n",
    "Answer (based only on the context provided):\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=rag_prompt_template,\n",
    "    input_variables=[\"context\", \"query\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ddfe3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install rank_bm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb979b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rank_bm25 import BM25Okapi\n",
    "import numpy as np\n",
    "\n",
    "def answer_with_hybrid_rag(query, n_results=5):\n",
    "    # 1. Semantic search with ChromaDB\n",
    "    semantic_results = collection.query(\n",
    "        query_texts=[query],\n",
    "        n_results=n_results,\n",
    "        include=[\"documents\", \"metadatas\", \"distances\"]\n",
    "    )\n",
    "    \n",
    "    # 2. Perform keyword search with BM25\n",
    "    # First get all documents to search across\n",
    "    all_docs = collection.get(\n",
    "        limit=100,  # Adjust based on your collection size\n",
    "        include=[\"documents\", \"metadatas\"]\n",
    "    )\n",
    "    \n",
    "    # Tokenize for BM25\n",
    "    tokenized_docs = [doc.split() for doc in all_docs[\"documents\"]]\n",
    "    bm25 = BM25Okapi(tokenized_docs)\n",
    "    \n",
    "    # Get BM25 scores\n",
    "    tokenized_query = query.split()\n",
    "    bm25_scores = bm25.get_scores(tokenized_query)\n",
    "    \n",
    "    # Get top BM25 results\n",
    "    top_bm25_indices = np.argsort(bm25_scores)[-n_results:][::-1]\n",
    "    \n",
    "    # 3. Combine results (simple union)\n",
    "    combined_docs = []\n",
    "    combined_meta = []\n",
    "    combined_ids = [] \n",
    "    seen_ids = set()\n",
    "    \n",
    "    # Add semantic results\n",
    "    for doc, meta, doc_id in zip(\n",
    "        semantic_results[\"documents\"][0], \n",
    "        semantic_results[\"metadatas\"][0],\n",
    "        semantic_results[\"ids\"][0]\n",
    "    ):\n",
    "        if doc_id not in seen_ids:\n",
    "            combined_docs.append(doc)\n",
    "            combined_meta.append(meta)\n",
    "            combined_ids.append(doc_id)\n",
    "            seen_ids.add(doc_id)\n",
    "    \n",
    "    # Add keyword results\n",
    "    for idx in top_bm25_indices:\n",
    "        doc_id = all_docs[\"ids\"][idx]\n",
    "        if doc_id not in seen_ids:\n",
    "            combined_docs.append(all_docs[\"documents\"][idx])\n",
    "            combined_meta.append(all_docs[\"metadatas\"][idx])\n",
    "            combined_ids.append(doc_id)\n",
    "            seen_ids.add(doc_id)\n",
    "    \n",
    "    # Limit to n_results total\n",
    "    combined_docs = combined_docs[:n_results]\n",
    "    combined_meta = combined_meta[:n_results]\n",
    "    combined_ids = combined_ids[:n_results]\n",
    "    \n",
    "    # Format context and complete RAG as before\n",
    "    formatted_docs = []\n",
    "    for doc, meta in zip(combined_docs, combined_meta):\n",
    "        page_num = meta.get(\"page_number\", \"unknown\")\n",
    "        formatted_docs.append(f\"[Page {page_num}]: {doc}\")\n",
    "    \n",
    "    context = \"\\n\\n---\\n\\n\".join(formatted_docs)\n",
    "    filled_prompt = prompt.format(context=context, query=query)\n",
    "    response = llm.invoke(filled_prompt)\n",
    "    \n",
    "    # Create a mock results object for print_results compatibility\n",
    "    mock_results = {\n",
    "        \"documents\": [combined_docs],\n",
    "        \"metadatas\": [combined_meta],\n",
    "        \"distances\": [[0.0] * len(combined_docs)],  # Placeholder distances\n",
    "        \"ids\": [combined_ids]\n",
    "    }\n",
    "    \n",
    "    return {\n",
    "        \"query\": query,\n",
    "        \"answer\": response.content if hasattr(response, 'content') else str(response),\n",
    "        \"source_documents\": mock_results\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960bba69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is the relationship between Brutus and Caesar?\n",
      "\n",
      "Answer: According to the context, Brutus and Caesar have a close relationship. In Act 3, Scene 1, Antony says that Caesar loved Brutus dearly, referring to him as Caesar's \"angel\" (Page 68). Additionally, Brutus is described as having stabbed Caesar, which suggests a level of intimacy and betrayal (Page 68). Furthermore, in Act 2, Scene 4, a warning is given to Caesar to \"beware of Brutus\" (Page 47), implying that Brutus poses a threat to Caesar. Overall, the relationship between Brutus and Caesar appears to be complex, with Brutus being both close to and a threat to Caesar.\n",
      "\n",
      "Sources:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━┳━━━━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Rank   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Document ID           </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Document Text                                                </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Page </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Distance </span>┃\n",
       "┡━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━╇━━━━━━━━━━┩\n",
       "│ 1      │ julius-caesar_chunk_… │ 23                                                           │ 17   │ 0.0000   │\n",
       "│        │                       │ Julius Caesar                                                │      │          │\n",
       "│        │                       │ ACT 1. SC. 2                                                 │      │          │\n",
       "│        │                       │ BRUTUS                                                       │      │          │\n",
       "│        │                       │  “Brutus” and “Caesar”—what should be in that                │      │          │\n",
       "│        │                       │  “Caesar”? Why sh...                                         │      │          │\n",
       "│ 2      │ julius-caesar_chunk_… │ 85                                                           │ 47   │ 0.0000   │\n",
       "│        │                       │ Julius Caesar                                                │      │          │\n",
       "│        │                       │ ACT 2. SC. 4                                                 │      │          │\n",
       "│        │                       │ ARTEMIDORUS                                                  │      │          │\n",
       "│        │                       │  Thy lover,                                                  │      │          │\n",
       "│        │                       │  Artemidorus                                                 │      │          │\n",
       "│        │                       │ He exits. PORTIA                                             │      │          │\n",
       "│        │                       │ LUCIUS                                                       │      │          │\n",
       "│        │                       │ PORTIA                                                       │      │          │\n",
       "│        │                       │ En...                                                        │      │          │\n",
       "│ 3      │ julius-caesar_chunk_… │ Bear back! If you have tears, prepare to shed them now. You  │ 68   │ 0.0000   │\n",
       "│        │                       │ all do know this mantle. I remember                          │      │          │\n",
       "│        │                       │  The...                                                      │      │          │\n",
       "│ 4      │ julius-caesar_chunk_… │ 109                                                          │ 58   │ 0.0000   │\n",
       "│        │                       │ Julius Caesar                                                │      │          │\n",
       "│        │                       │ ACT 3. SC. 1                                                 │      │          │\n",
       "│        │                       │ CASSIUS                                                      │      │          │\n",
       "│        │                       │ ANTONY                                                       │      │          │\n",
       "│        │                       │ CASSIUS                                                      │      │          │\n",
       "│        │                       │ ANTONY                                                       │      │          │\n",
       "│        │                       │ BRUTUS                                                       │      │          │\n",
       "│        │                       │  Either a coward or a flatterer....                          │      │          │\n",
       "│ 5      │ julius-caesar_chunk_… │ 199                                                          │ 101  │ 0.0000   │\n",
       "│        │                       │ Julius Caesar                                                │      │          │\n",
       "│        │                       │ ACT 5. SC. 4                                                 │      │          │\n",
       "│        │                       │ They exit. BRUTUS                                            │      │          │\n",
       "│        │                       │ Brutus, Messala, and Flavius exit. CATO                      │      │          │\n",
       "│        │                       │ LUCILIUS                                                     │      │          │\n",
       "│        │                       │ Ca...                                                        │      │          │\n",
       "└────────┴───────────────────────┴──────────────────────────────────────────────────────────────┴──────┴──────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━┳━━━━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35mRank  \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mDocument ID          \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mDocument Text                                               \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mPage\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mDistance\u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━╇━━━━━━━━━━┩\n",
       "│ 1      │ julius-caesar_chunk_… │ 23                                                           │ 17   │ 0.0000   │\n",
       "│        │                       │ Julius Caesar                                                │      │          │\n",
       "│        │                       │ ACT 1. SC. 2                                                 │      │          │\n",
       "│        │                       │ BRUTUS                                                       │      │          │\n",
       "│        │                       │  “Brutus” and “Caesar”—what should be in that                │      │          │\n",
       "│        │                       │  “Caesar”? Why sh...                                         │      │          │\n",
       "│ 2      │ julius-caesar_chunk_… │ 85                                                           │ 47   │ 0.0000   │\n",
       "│        │                       │ Julius Caesar                                                │      │          │\n",
       "│        │                       │ ACT 2. SC. 4                                                 │      │          │\n",
       "│        │                       │ ARTEMIDORUS                                                  │      │          │\n",
       "│        │                       │  Thy lover,                                                  │      │          │\n",
       "│        │                       │  Artemidorus                                                 │      │          │\n",
       "│        │                       │ He exits. PORTIA                                             │      │          │\n",
       "│        │                       │ LUCIUS                                                       │      │          │\n",
       "│        │                       │ PORTIA                                                       │      │          │\n",
       "│        │                       │ En...                                                        │      │          │\n",
       "│ 3      │ julius-caesar_chunk_… │ Bear back! If you have tears, prepare to shed them now. You  │ 68   │ 0.0000   │\n",
       "│        │                       │ all do know this mantle. I remember                          │      │          │\n",
       "│        │                       │  The...                                                      │      │          │\n",
       "│ 4      │ julius-caesar_chunk_… │ 109                                                          │ 58   │ 0.0000   │\n",
       "│        │                       │ Julius Caesar                                                │      │          │\n",
       "│        │                       │ ACT 3. SC. 1                                                 │      │          │\n",
       "│        │                       │ CASSIUS                                                      │      │          │\n",
       "│        │                       │ ANTONY                                                       │      │          │\n",
       "│        │                       │ CASSIUS                                                      │      │          │\n",
       "│        │                       │ ANTONY                                                       │      │          │\n",
       "│        │                       │ BRUTUS                                                       │      │          │\n",
       "│        │                       │  Either a coward or a flatterer....                          │      │          │\n",
       "│ 5      │ julius-caesar_chunk_… │ 199                                                          │ 101  │ 0.0000   │\n",
       "│        │                       │ Julius Caesar                                                │      │          │\n",
       "│        │                       │ ACT 5. SC. 4                                                 │      │          │\n",
       "│        │                       │ They exit. BRUTUS                                            │      │          │\n",
       "│        │                       │ Brutus, Messala, and Flavius exit. CATO                      │      │          │\n",
       "│        │                       │ LUCILIUS                                                     │      │          │\n",
       "│        │                       │ Ca...                                                        │      │          │\n",
       "└────────┴───────────────────────┴──────────────────────────────────────────────────────────────┴──────┴──────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test our RAG pipeline with a question\n",
    "test_query = \"What is the relationship between Brutus and Caesar?\"\n",
    "response = answer_with_hybrid_rag(test_query)\n",
    "\n",
    "print(f\"Question: {test_query}\")\n",
    "print(f\"\\nAnswer: {response['answer']}\")\n",
    "print(\"\\nSources:\")\n",
    "print_results(response[\"source_documents\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d52efee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Question: What are the main themes in Julius Caesar?\n",
      "\n",
      "Answer: I don't have enough information to answer this question. The context provided only includes excerpts from specific scenes in Julius Caesar and does not provide a comprehensive overview of the play's themes.\n",
      "\n",
      "Top source:\n",
      "[Page 51]:\n",
      "95\n",
      "Julius Caesar\n",
      "ACT 3. SC. 1\n",
      "POPILIUS\n",
      "CASSIUS\n",
      "POPILIUS\n",
      "He walks away. BRUTUS\n",
      "CASSIUS\n",
      "BRUTUS\n",
      "CASSIUS\n",
      "BRUTUS\n",
      "CASSIUS\n",
      "Trebonius and Antony exit. DECIUS\n",
      "BRUTUS\n",
      "CINNA\n",
      "CAESAR\n",
      "METELLUS\n",
      ", to Cassius\n",
      " \n",
      " I wis...\n",
      "\n",
      "==================================================\n",
      "Question: How does Brutus justify killing Caesar?\n",
      "\n",
      "Answer: I don't have enough information to answer this question. The context provided only includes excerpts from specific scenes in Julius Caesar and does not provide a comprehensive overview of the play's themes.\n",
      "\n",
      "Top source:\n",
      "[Page 51]:\n",
      "95\n",
      "Julius Caesar\n",
      "ACT 3. SC. 1\n",
      "POPILIUS\n",
      "CASSIUS\n",
      "POPILIUS\n",
      "He walks away. BRUTUS\n",
      "CASSIUS\n",
      "BRUTUS\n",
      "CASSIUS\n",
      "BRUTUS\n",
      "CASSIUS\n",
      "Trebonius and Antony exit. DECIUS\n",
      "BRUTUS\n",
      "CINNA\n",
      "CAESAR\n",
      "METELLUS\n",
      ", to Cassius\n",
      " \n",
      " I wis...\n",
      "\n",
      "==================================================\n",
      "Question: How does Brutus justify killing Caesar?\n",
      "\n",
      "Answer: According to the context, Brutus justifies killing Caesar by stating that he did it \"for the good of Rome\" (Page 63, ACT 3. SC. 2). He also mentions that he has \"the same dagger for myself when it shall please my country to need my death\", implying that he is willing to sacrifice himself for Rome if necessary. However, the full reasoning behind Brutus' actions is not fully explained in the provided context.\n",
      "\n",
      "Top source:\n",
      "[Page 63]:\n",
      "119\n",
      "Julius Caesar\n",
      "ACT 3. SC. 2\n",
      "PLEBEIANS\n",
      "FIRST PLEBEIAN\n",
      "SECOND PLEBEIAN\n",
      "THIRD PLEBEIAN\n",
      "FOURTH PLEBEIAN\n",
      "FIRST PLEBEIAN\n",
      "BRUTUS\n",
      "SECOND PLEBEIAN\n",
      "FIRST PLEBEIAN\n",
      "BRUTUS\n",
      " more to Caesar than you shall do to ...\n",
      "\n",
      "==================================================\n",
      "Question: What role does Cassius play in the conspiracy?\n",
      "\n",
      "Answer: According to the context, Brutus justifies killing Caesar by stating that he did it \"for the good of Rome\" (Page 63, ACT 3. SC. 2). He also mentions that he has \"the same dagger for myself when it shall please my country to need my death\", implying that he is willing to sacrifice himself for Rome if necessary. However, the full reasoning behind Brutus' actions is not fully explained in the provided context.\n",
      "\n",
      "Top source:\n",
      "[Page 63]:\n",
      "119\n",
      "Julius Caesar\n",
      "ACT 3. SC. 2\n",
      "PLEBEIANS\n",
      "FIRST PLEBEIAN\n",
      "SECOND PLEBEIAN\n",
      "THIRD PLEBEIAN\n",
      "FOURTH PLEBEIAN\n",
      "FIRST PLEBEIAN\n",
      "BRUTUS\n",
      "SECOND PLEBEIAN\n",
      "FIRST PLEBEIAN\n",
      "BRUTUS\n",
      " more to Caesar than you shall do to ...\n",
      "\n",
      "==================================================\n",
      "Question: What role does Cassius play in the conspiracy?\n",
      "\n",
      "Answer: Cassius appears to be a key figure in the conspiracy against Caesar. He is the one who \"first did whet\" the speaker (likely Brutus) \"against Caesar\" ([Page 31]), suggesting that Cassius played a role in convincing Brutus to join the conspiracy. Additionally, Cassius is shown to be interacting with other conspirators, such as Brutus and Metellus Cimber, and is concerned about the potential discovery of their plan ([Page 51]). However, the exact nature and extent of Cassius' role in the conspiracy are not fully elaborated upon in the provided context.\n",
      "\n",
      "Top source:\n",
      "[Page 31]:\n",
      "Go to the gate; somebody knocks. Since Cassius first did whet me against Caesar,\n",
      " I have not slept. Between the acting of a dreadful thing\n",
      " And the first motion, all the interim is\n",
      " Like a phantasma o...\n",
      "\n",
      "Results exported to ../RAG Results/multiquery_rag_results.txt\n",
      "\n",
      "Answer: Cassius appears to be a key figure in the conspiracy against Caesar. He is the one who \"first did whet\" the speaker (likely Brutus) \"against Caesar\" ([Page 31]), suggesting that Cassius played a role in convincing Brutus to join the conspiracy. Additionally, Cassius is shown to be interacting with other conspirators, such as Brutus and Metellus Cimber, and is concerned about the potential discovery of their plan ([Page 51]). However, the exact nature and extent of Cassius' role in the conspiracy are not fully elaborated upon in the provided context.\n",
      "\n",
      "Top source:\n",
      "[Page 31]:\n",
      "Go to the gate; somebody knocks. Since Cassius first did whet me against Caesar,\n",
      " I have not slept. Between the acting of a dreadful thing\n",
      " And the first motion, all the interim is\n",
      " Like a phantasma o...\n",
      "\n",
      "Results exported to ../RAG Results/multiquery_rag_results.txt\n"
     ]
    }
   ],
   "source": [
    "# Test with multiple questions to evaluate system\n",
    "results_for_export = []\n",
    "\n",
    "test_questions = [\n",
    "    \"What are the main themes in Julius Caesar?\",\n",
    "    \"How does Brutus justify killing Caesar?\",\n",
    "    \"What role does Cassius play in the conspiracy?\"\n",
    "]\n",
    "\n",
    "for question in test_questions:\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(f\"Question: {question}\")\n",
    "    response = answer_with_hybrid_rag(question)\n",
    "    print(f\"\\nAnswer: {response['answer']}\")\n",
    "    print(\"\\nTop source:\")\n",
    "    if len(response[\"source_documents\"][\"documents\"][0]) > 0:\n",
    "        top_doc = response[\"source_documents\"][\"documents\"][0][0]\n",
    "        top_meta = response[\"source_documents\"][\"metadatas\"][0][0]\n",
    "        page = top_meta.get(\"page_number\", \"N/A\")\n",
    "        print(f\"[Page {page}]:\\n{top_doc[:200]}...\")  # Print first 200 chars\n",
    "        # Save for export\n",
    "        results_for_export.append({\n",
    "            \"question\": question,\n",
    "            \"answer\": response['answer'],\n",
    "            \"page\": page,\n",
    "            \"chunk\": top_doc\n",
    "        })\n",
    "    else:\n",
    "        print(\"No sources found.\")\n",
    "        results_for_export.append({\n",
    "            \"question\": question,\n",
    "            \"answer\": response['answer'],\n",
    "            \"page\": None,\n",
    "            \"chunk\": None\n",
    "        })\n",
    "\n",
    "# Export results to a well-formatted text file\n",
    "with open(multiquery_rag_output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"RAG Multi-Query Evaluation Results\\n\")\n",
    "    f.write(\"=\"*60 + \"\\n\\n\")\n",
    "    for idx, res in enumerate(results_for_export, 1):\n",
    "        f.write(f\"Question {idx}: {res['question']}\\n\")\n",
    "        f.write(f\"Answer:\\n{res['answer']}\\n\\n\")\n",
    "        if res[\"chunk\"]:\n",
    "            f.write(f\"Top Source Chunk (Page {res['page']}):\\n{res['chunk']}\\n\")\n",
    "        else:\n",
    "            f.write(\"Top Source Chunk: No sources found.\\n\")\n",
    "        f.write(\"-\"*60 + \"\\n\\n\")\n",
    "print(f\"\\nResults exported to {multiquery_rag_output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742c3905",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Cannot install langchain-community==0.2.17, langchain-core==0.2.38 and langchain==0.2.16 because these package versions have conflicting dependencies.\n",
      "ERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/topics/dependency-resolution/#dealing-with-dependency-conflicts\n"
     ]
    }
   ],
   "source": [
    "# !pip install \"ragas>=0.2.0,<0.3.0\" --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c56031",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'is_data_content_block' from 'langchain_core.messages' (c:\\Users\\micro\\Anaconda3\\envs\\NLP_2\\Lib\\site-packages\\langchain_core\\messages\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dataset\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgroq\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Groq\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mragas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m evaluate\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mragas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m faithfulness, answer_relevancy\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mragas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membeddings\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HuggingfaceEmbeddings\n",
      "File \u001b[1;32mc:\\Users\\micro\\Anaconda3\\envs\\NLP_2\\Lib\\site-packages\\ragas\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mragas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcache\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CacheInterface, DiskCacheBackend, cacher\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mragas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset_schema\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m EvaluationDataset, MultiTurnSample, SingleTurnSample\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mragas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mevaluation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m evaluate\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mragas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrun_config\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RunConfig\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\micro\\Anaconda3\\envs\\NLP_2\\Lib\\site-packages\\ragas\\evaluation.py:20\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mragas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChainType, RagasTracer, new_group\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mragas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset_schema\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     15\u001b[0m     EvaluationDataset,\n\u001b[0;32m     16\u001b[0m     EvaluationResult,\n\u001b[0;32m     17\u001b[0m     MultiTurnSample,\n\u001b[0;32m     18\u001b[0m     SingleTurnSample,\n\u001b[0;32m     19\u001b[0m )\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mragas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membeddings\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     21\u001b[0m     BaseRagasEmbeddings,\n\u001b[0;32m     22\u001b[0m     LangchainEmbeddingsWrapper,\n\u001b[0;32m     23\u001b[0m     embedding_factory,\n\u001b[0;32m     24\u001b[0m )\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mragas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ExceptionInRunner\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mragas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexecutor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Executor\n",
      "File \u001b[1;32mc:\\Users\\micro\\Anaconda3\\envs\\NLP_2\\Lib\\site-packages\\ragas\\embeddings\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mragas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membeddings\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      2\u001b[0m     BaseRagasEmbeddings,\n\u001b[0;32m      3\u001b[0m     HuggingfaceEmbeddings,\n\u001b[0;32m      4\u001b[0m     LangchainEmbeddingsWrapper,\n\u001b[0;32m      5\u001b[0m     LlamaIndexEmbeddingsWrapper,\n\u001b[0;32m      6\u001b[0m     embedding_factory,\n\u001b[0;32m      7\u001b[0m )\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mragas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membeddings\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhaystack_wrapper\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HaystackEmbeddingsWrapper\n\u001b[0;32m     10\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBaseRagasEmbeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHaystackEmbeddingsWrapper\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membedding_factory\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     17\u001b[0m ]\n",
      "File \u001b[1;32mc:\\Users\\micro\\Anaconda3\\envs\\NLP_2\\Lib\\site-packages\\ragas\\embeddings\\base.py:10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membeddings\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Embeddings\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_openai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membeddings\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OpenAIEmbeddings\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpydantic\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataclasses\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dataclass\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpydantic_core\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CoreSchema, core_schema\n",
      "File \u001b[1;32mc:\\Users\\micro\\Anaconda3\\envs\\NLP_2\\Lib\\site-packages\\langchain_openai\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"Module for OpenAI integrations.\"\"\"\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_openai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchat_models\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AzureChatOpenAI, ChatOpenAI\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_openai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membeddings\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AzureOpenAIEmbeddings, OpenAIEmbeddings\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_openai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AzureOpenAI, OpenAI\n",
      "File \u001b[1;32mc:\\Users\\micro\\Anaconda3\\envs\\NLP_2\\Lib\\site-packages\\langchain_openai\\chat_models\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"Module for OpenAI chat models.\"\"\"\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_openai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchat_models\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mazure\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AzureChatOpenAI\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_openai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchat_models\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatOpenAI\n\u001b[0;32m      6\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAzureChatOpenAI\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChatOpenAI\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\micro\\Anaconda3\\envs\\NLP_2\\Lib\\site-packages\\langchain_openai\\chat_models\\azure.py:20\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpydantic\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaseModel, Field, SecretStr, model_validator\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping_extensions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Self\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_openai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchat_models\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaseChatOpenAI\n\u001b[0;32m     22\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m     25\u001b[0m _BM \u001b[38;5;241m=\u001b[39m TypeVar(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_BM\u001b[39m\u001b[38;5;124m\"\u001b[39m, bound\u001b[38;5;241m=\u001b[39mBaseModel)\n",
      "File \u001b[1;32mc:\\Users\\micro\\Anaconda3\\envs\\NLP_2\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py:48\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlanguage_models\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LanguageModelInput\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlanguage_models\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchat_models\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     45\u001b[0m     BaseChatModel,\n\u001b[0;32m     46\u001b[0m     LangSmithParams,\n\u001b[0;32m     47\u001b[0m )\n\u001b[1;32m---> 48\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmessages\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     49\u001b[0m     AIMessage,\n\u001b[0;32m     50\u001b[0m     AIMessageChunk,\n\u001b[0;32m     51\u001b[0m     BaseMessage,\n\u001b[0;32m     52\u001b[0m     BaseMessageChunk,\n\u001b[0;32m     53\u001b[0m     ChatMessage,\n\u001b[0;32m     54\u001b[0m     ChatMessageChunk,\n\u001b[0;32m     55\u001b[0m     FunctionMessage,\n\u001b[0;32m     56\u001b[0m     FunctionMessageChunk,\n\u001b[0;32m     57\u001b[0m     HumanMessage,\n\u001b[0;32m     58\u001b[0m     HumanMessageChunk,\n\u001b[0;32m     59\u001b[0m     InvalidToolCall,\n\u001b[0;32m     60\u001b[0m     SystemMessage,\n\u001b[0;32m     61\u001b[0m     SystemMessageChunk,\n\u001b[0;32m     62\u001b[0m     ToolCall,\n\u001b[0;32m     63\u001b[0m     ToolMessage,\n\u001b[0;32m     64\u001b[0m     ToolMessageChunk,\n\u001b[0;32m     65\u001b[0m     is_data_content_block,\n\u001b[0;32m     66\u001b[0m )\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmessages\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m content \u001b[38;5;28;01mas\u001b[39;00m types\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmessages\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     69\u001b[0m     InputTokenDetails,\n\u001b[0;32m     70\u001b[0m     OutputTokenDetails,\n\u001b[0;32m     71\u001b[0m     UsageMetadata,\n\u001b[0;32m     72\u001b[0m )\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'is_data_content_block' from 'langchain_core.messages' (c:\\Users\\micro\\Anaconda3\\envs\\NLP_2\\Lib\\site-packages\\langchain_core\\messages\\__init__.py)"
     ]
    }
   ],
   "source": [
    "# === Groq + RAG + RAGAS Evaluation ===\n",
    "# Prereqs:\n",
    "# pip install ragas datasets groq tqdm sentence-transformers numpy\n",
    "\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import time\n",
    "import asyncio\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from datasets import Dataset\n",
    "from groq import Groq\n",
    "\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import faithfulness, answer_relevancy\n",
    "from ragas.embeddings.base import HuggingfaceEmbeddings\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain_core.prompt_values import PromptValue\n",
    "from langchain_core.outputs import Generation, LLMResult\n",
    "\n",
    "\n",
    "# ==== CONFIG ====\n",
    "# Use the API key already set in previous cell\n",
    "groq_client = Groq(api_key=os.environ[\"GROQ_API_KEY\"])\n",
    "\n",
    "testbed_path = \"../RAG Results/test_bed.json\"\n",
    "output_metrics_path = \"../RAG Results/multiquery_rag_metrics.txt\"\n",
    "cached_answers_path = \"../RAG Results/cached_rag_answers.json\"  # NEW: Cache file\n",
    "TOP_K = 3\n",
    "\n",
    "GROQ_RAG_MODEL = \"llama-3.3-70b-versatile\"\n",
    "GROQ_RAGAS_MODEL = \"llama-3.3-70b-versatile\"\n",
    "EMBED_MODEL = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "\n",
    "# Rate limiting config for llama-3.3-70b-versatile:\n",
    "# RPM: 30 (requests per minute)\n",
    "# RPD: 1,000 (requests per day)\n",
    "# TPM: 12,000 (tokens per minute)\n",
    "# TPD: 100,000 (tokens per day)\n",
    "REQUEST_DELAY = 2.5  # seconds between requests (allows ~24 RPM, safe margin below 30 RPM)\n",
    "BATCH_SIZE = 5  # Process in small batches to avoid hitting token limits\n",
    "MAX_RETRIES = 3  # Retry failed requests\n",
    "\n",
    "print(\"Exists:\", os.path.exists(testbed_path))\n",
    "print(\"Size:\", os.path.getsize(testbed_path), \"bytes\")\n",
    "\n",
    "with open(testbed_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    first_200 = f.read(200)\n",
    "print(\"First few characters:\\n\", first_200)\n",
    "\n",
    "\n",
    "# ==== 1️⃣ Load test data ====\n",
    "with open(testbed_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    test_data = json.load(f)\n",
    "\n",
    "print(f\"[INFO] Loaded {len(test_data)} QA pairs from testbed.\")\n",
    "\n",
    "\n",
    "# ==== 2️⃣ Groq generation with retry logic ====\n",
    "def generate_with_groq(prompt, model_name=GROQ_RAG_MODEL, retries=MAX_RETRIES):\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            chat_completion = groq_client.chat.completions.create(\n",
    "                messages=[\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": prompt,\n",
    "                    }\n",
    "                ],\n",
    "                model=model_name,\n",
    "                temperature=0.7,\n",
    "            )\n",
    "            time.sleep(REQUEST_DELAY)\n",
    "            return chat_completion.choices[0].message.content.strip()\n",
    "        except Exception as e:\n",
    "            if \"rate_limit\" in str(e).lower():\n",
    "                wait_time = REQUEST_DELAY * (attempt + 2)  # Exponential backoff\n",
    "                print(f\"[WARN] Rate limit hit. Waiting {wait_time}s before retry {attempt + 1}/{retries}\")\n",
    "                time.sleep(wait_time)\n",
    "            else:\n",
    "                print(f\"[ERROR] Groq API call failed (attempt {attempt + 1}): {e}\")\n",
    "                if attempt == retries - 1:\n",
    "                    time.sleep(REQUEST_DELAY)\n",
    "                    return None\n",
    "                time.sleep(REQUEST_DELAY)\n",
    "    return None\n",
    "\n",
    "\n",
    "# ==== 3️⃣ Groq wrapper for RAGAS following BaseRagasLLM interface ====\n",
    "from ragas.llms.base import BaseRagasLLM as RagasBaseLLM\n",
    "from ragas.run_config import RunConfig\n",
    "\n",
    "class GroqRagasLLM(RagasBaseLLM):\n",
    "    \"\"\"Groq LLM wrapper implementing RAGAS BaseRagasLLM interface.\"\"\"\n",
    "    \n",
    "    def __init__(self, model_name):\n",
    "        super().__init__(run_config=RunConfig())\n",
    "        self.model_name = model_name\n",
    "        self.client = Groq(api_key=os.environ[\"GROQ_API_KEY\"])\n",
    "        self.request_count = 0\n",
    "        self.last_request_time = time.time()\n",
    "\n",
    "    def _rate_limit_check(self):\n",
    "        \"\"\"Ensure we don't exceed rate limits\"\"\"\n",
    "        current_time = time.time()\n",
    "        time_since_last = current_time - self.last_request_time\n",
    "        \n",
    "        # Ensure minimum delay between requests\n",
    "        if time_since_last < REQUEST_DELAY:\n",
    "            sleep_time = REQUEST_DELAY - time_since_last\n",
    "            time.sleep(sleep_time)\n",
    "        \n",
    "        self.last_request_time = time.time()\n",
    "        self.request_count += 1\n",
    "\n",
    "    def _extract_text_from_prompt(self, prompt: PromptValue) -> str:\n",
    "        \"\"\"Extract text from PromptValue object.\"\"\"\n",
    "        # PromptValue has .to_string() method\n",
    "        if hasattr(prompt, \"to_string\"):\n",
    "            return prompt.to_string()\n",
    "        # Fallback to string conversion\n",
    "        return str(prompt)\n",
    "\n",
    "    def generate_text(\n",
    "        self,\n",
    "        prompt: PromptValue,\n",
    "        n: int = 1,\n",
    "        temperature: float = 0.01,\n",
    "        stop=None,\n",
    "        callbacks=None,\n",
    "    ) -> LLMResult:\n",
    "        \"\"\"Synchronous generation - required by BaseRagasLLM.\"\"\"\n",
    "        prompt_text = self._extract_text_from_prompt(prompt)\n",
    "        generations = []\n",
    "        \n",
    "        for i in range(n):\n",
    "            for attempt in range(MAX_RETRIES):\n",
    "                try:\n",
    "                    # Rate limit check\n",
    "                    self._rate_limit_check()\n",
    "                    \n",
    "                    chat_completion = self.client.chat.completions.create(\n",
    "                        messages=[{\"role\": \"user\", \"content\": prompt_text}],\n",
    "                        model=self.model_name,\n",
    "                        temperature=temperature,\n",
    "                    )\n",
    "                    \n",
    "                    text = chat_completion.choices[0].message.content.strip()\n",
    "                    generations.append([Generation(text=text)])\n",
    "                    break  # Success\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    if \"rate_limit\" in str(e).lower() and attempt < MAX_RETRIES - 1:\n",
    "                        wait_time = REQUEST_DELAY * (attempt + 2)\n",
    "                        print(f\"[WARN] Rate limit hit. Waiting {wait_time}s (attempt {attempt + 1})\")\n",
    "                        time.sleep(wait_time)\n",
    "                    else:\n",
    "                        print(f\"[ERROR] Failed (attempt {attempt + 1}): {e}\")\n",
    "                        if attempt == MAX_RETRIES - 1:\n",
    "                            generations.append([Generation(text=f\"[Error: {e}]\")])\n",
    "                        else:\n",
    "                            time.sleep(REQUEST_DELAY)\n",
    "        \n",
    "        return LLMResult(generations=generations)\n",
    "\n",
    "    async def agenerate_text(\n",
    "        self,\n",
    "        prompt: PromptValue,\n",
    "        n: int = 1,\n",
    "        temperature: float = 0.01,\n",
    "        stop=None,\n",
    "        callbacks=None,\n",
    "    ) -> LLMResult:\n",
    "        \"\"\"Asynchronous generation - required by BaseRagasLLM.\"\"\"\n",
    "        prompt_text = self._extract_text_from_prompt(prompt)\n",
    "        generations = []\n",
    "        \n",
    "        for i in range(n):\n",
    "            for attempt in range(MAX_RETRIES):\n",
    "                try:\n",
    "                    # Rate limit check\n",
    "                    await asyncio.sleep(REQUEST_DELAY)\n",
    "                    \n",
    "                    # Run blocking SDK call in thread\n",
    "                    chat_completion = await asyncio.to_thread(\n",
    "                        self.client.chat.completions.create,\n",
    "                        messages=[{\"role\": \"user\", \"content\": prompt_text}],\n",
    "                        model=self.model_name,\n",
    "                        temperature=temperature,\n",
    "                    )\n",
    "                    \n",
    "                    text = chat_completion.choices[0].message.content.strip()\n",
    "                    generations.append([Generation(text=text)])\n",
    "                    break  # Success\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    if \"rate_limit\" in str(e).lower() and attempt < MAX_RETRIES - 1:\n",
    "                        wait_time = REQUEST_DELAY * (attempt + 2)\n",
    "                        print(f\"[WARN] Rate limit hit. Waiting {wait_time}s (attempt {attempt + 1})\")\n",
    "                        await asyncio.sleep(wait_time)\n",
    "                    else:\n",
    "                        print(f\"[ERROR] Failed (attempt {attempt + 1}): {e}\")\n",
    "                        if attempt == MAX_RETRIES - 1:\n",
    "                            generations.append([Generation(text=f\"[Error: {e}]\")])\n",
    "                        else:\n",
    "                            await asyncio.sleep(REQUEST_DELAY)\n",
    "        \n",
    "        return LLMResult(generations=generations)\n",
    "\n",
    "    def is_finished(self, response: LLMResult) -> bool:\n",
    "        \"\"\"Check if response is complete - required by BaseRagasLLM.\"\"\"\n",
    "        return True\n",
    "\n",
    "\n",
    "# ==== 4️⃣ Check collection availability ====\n",
    "try:\n",
    "    collection.query(query_texts=[\"test\"], n_results=1)\n",
    "except NameError:\n",
    "    print(\"\\n[CRITICAL WARNING] The 'collection' object (ChromaDB) is NOT defined.\")\n",
    "    print(\"Please initialize your ChromaDB client/collection before running this cell.\")\n",
    "    raise SystemExit\n",
    "\n",
    "\n",
    "# ==== 5️⃣ Generate records with caching and rate limiting ====\n",
    "records = []\n",
    "\n",
    "# Check if cached answers exist\n",
    "if os.path.exists(cached_answers_path):\n",
    "    print(f\"[INFO] Found cached answers at '{cached_answers_path}'\")\n",
    "    try:\n",
    "        with open(cached_answers_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            cached_data = json.load(f)\n",
    "        \n",
    "        # Validate cache matches current test data\n",
    "        if len(cached_data) == len(test_data):\n",
    "            questions_match = all(\n",
    "                cached_data[i][\"question\"] == test_data[i][\"question\"] \n",
    "                for i in range(len(test_data))\n",
    "            )\n",
    "            \n",
    "            if questions_match:\n",
    "                print(f\"[INFO] Loading {len(cached_data)} cached answers (skipping generation)\")\n",
    "                records = cached_data\n",
    "            else:\n",
    "                print(\"[WARN] Cached questions don't match test data. Regenerating...\")\n",
    "        else:\n",
    "            print(f\"[WARN] Cache size mismatch ({len(cached_data)} vs {len(test_data)}). Regenerating...\")\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Failed to load cache: {e}. Regenerating...\")\n",
    "\n",
    "# Generate new answers if cache not usable\n",
    "if not records:\n",
    "    print(f\"[INFO] Generating RAG answers with rate limiting (max 30 RPM)...\")\n",
    "    print(f\"[INFO] Request delay: {REQUEST_DELAY}s | Batch size: {BATCH_SIZE}\")\n",
    "    \n",
    "    for item in tqdm(test_data, desc=\"Generating Groq RAG answers\"):\n",
    "        question = item[\"question\"]\n",
    "        ideal_answer = item[\"ideal_answer\"]\n",
    "\n",
    "        retrieved = collection.query(query_texts=[question], n_results=TOP_K)\n",
    "        retrieved_docs = retrieved[\"documents\"][0]\n",
    "        retrieved_context = \"\\n\".join(retrieved_docs)\n",
    "\n",
    "        prompt = (\n",
    "            f\"Context:\\n{retrieved_context}\\n\\n\"\n",
    "            f\"Question:\\n{question}\\n\\nAnswer:\"\n",
    "        )\n",
    "\n",
    "        generated_answer = generate_with_groq(prompt)\n",
    "        if not generated_answer:\n",
    "            generated_answer = f\"[Fallback mock answer] Context excerpt: {retrieved_docs[0][:150]}...\"\n",
    "\n",
    "        records.append({\n",
    "            \"question\": question,\n",
    "            \"contexts\": retrieved_docs,\n",
    "            \"answer\": generated_answer,\n",
    "            \"ground_truth\": ideal_answer,\n",
    "        })\n",
    "        \n",
    "        # Progress update every 5 questions\n",
    "        if len(records) % 5 == 0:\n",
    "            print(f\"[INFO] Processed {len(records)}/{len(test_data)} questions\")\n",
    "    \n",
    "    # Save generated answers to cache\n",
    "    try:\n",
    "        os.makedirs(os.path.dirname(cached_answers_path), exist_ok=True)\n",
    "        with open(cached_answers_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(records, f, indent=2, ensure_ascii=False)\n",
    "        print(f\"[SUCCESS] Cached {len(records)} answers to '{cached_answers_path}'\")\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] Failed to save cache: {e}\")\n",
    "\n",
    "\n",
    "# ==== 6️⃣ Convert to HF Dataset ====\n",
    "dataset = Dataset.from_list(records)\n",
    "print(f\"[INFO] Created dataset with {len(dataset)} samples\")\n",
    "\n",
    "\n",
    "# ==== 7️⃣ Custom HuggingFace Embedding Wrapper ====\n",
    "class CustomHuggingfaceEmbeddings(HuggingfaceEmbeddings):\n",
    "    \"\"\"Implements both sync + async embedding methods for latest RAGAS.\"\"\"\n",
    "    def __init__(self, model_name: str):\n",
    "        # ✅ Do not call super()\n",
    "        self.model_name = model_name\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "\n",
    "    # --- Sync methods ---\n",
    "    def embed_documents(self, texts):\n",
    "        return self.model.encode(texts, show_progress_bar=False).tolist()\n",
    "\n",
    "    def embed_query(self, text):\n",
    "        return self.model.encode([text], show_progress_bar=False).tolist()[0]\n",
    "\n",
    "    # --- Async methods ---\n",
    "    async def aembed_documents(self, texts):\n",
    "        return self.embed_documents(texts)\n",
    "\n",
    "    async def aembed_query(self, text):\n",
    "        return self.embed_query(text)\n",
    "\n",
    "\n",
    "# ==== 8️⃣ Evaluate with RAGAS ====\n",
    "llm = GroqRagasLLM(GROQ_RAGAS_MODEL)\n",
    "embeddings = CustomHuggingfaceEmbeddings(model_name=EMBED_MODEL)\n",
    "\n",
    "print(f\"\\n[INFO] Starting RAGAS evaluation with {GROQ_RAGAS_MODEL}...\")\n",
    "print(f\"[INFO] Rate limits: 30 RPM | 12K TPM | Using {REQUEST_DELAY}s delays\")\n",
    "print(f\"[INFO] Estimated time: ~{len(dataset) * REQUEST_DELAY / 60:.1f} minutes\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "results = evaluate(\n",
    "    dataset=dataset,\n",
    "    metrics=[faithfulness, answer_relevancy],\n",
    "    llm=llm,\n",
    "    embeddings=embeddings\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(f\"\\n[SUCCESS] Evaluation completed in {elapsed_time / 60:.2f} minutes\")\n",
    "\n",
    "\n",
    "# ==== 9️⃣ Save Results ====\n",
    "faithfulness_scores = results[\"faithfulness\"]\n",
    "answer_relevancy_scores = results[\"answer_relevancy\"]\n",
    "\n",
    "# ✅ Compute mean values\n",
    "faithfulness_mean = float(np.mean(faithfulness_scores))\n",
    "answer_relevancy_mean = float(np.mean(answer_relevancy_scores))\n",
    "\n",
    "os.makedirs(os.path.dirname(output_metrics_path), exist_ok=True)\n",
    "\n",
    "with open(output_metrics_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"=== RAG Evaluation Metrics (Groq + RAGAS) ===\\n\")\n",
    "    f.write(f\"Timestamp: {datetime.now()}\\n\")\n",
    "    f.write(f\"Evaluation Duration: {elapsed_time / 60:.2f} minutes\\n\\n\")\n",
    "    f.write(f\"RAG Generation Model: {GROQ_RAG_MODEL}\\n\")\n",
    "    f.write(f\"RAGAS Evaluation Model: {GROQ_RAGAS_MODEL}\\n\")\n",
    "    f.write(f\"Rate Limiting: {REQUEST_DELAY}s delay between requests\\n\")\n",
    "    f.write(f\"Cached Answers: {os.path.basename(cached_answers_path)}\\n\\n\")\n",
    "    f.write(f\"Faithfulness (avg): {faithfulness_mean:.4f}\\n\")\n",
    "    f.write(f\"Answer Relevancy (avg): {answer_relevancy_mean:.4f}\\n\\n\")\n",
    "    f.write(\"Full Results:\\n\")\n",
    "    f.write(str(results))\n",
    "\n",
    "print(f\"\\n✅ Evaluation complete! Metrics saved to '{output_metrics_path}'\")\n",
    "print(f\"Faithfulness (avg): {faithfulness_mean:.4f} | Answer Relevancy (avg): {answer_relevancy_mean:.4f}\")\n",
    "print(f\"\\n[TIP] To regenerate answers, delete: {cached_answers_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ragas_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
